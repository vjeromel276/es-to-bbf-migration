{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES Order Data Quality Analysis\n",
    "\n",
    "This notebook pulls ALL active ES Orders and categorizes them by data issues for remediation.\n",
    "\n",
    "## Output: Excel file with tabs:\n",
    "1. **Summary** - Overall counts and issues\n",
    "2. **Ready_To_Migrate** - Orders with all required fields populated\n",
    "3. **Missing_BAN** - Orders missing Billing_Invoice__c (CRITICAL - cannot migrate)\n",
    "4. **Missing_A_Location** - Orders missing Address_A__c\n",
    "5. **Missing_Node** - Orders missing Node__c (can be post-migration)\n",
    "6. **Missing_Service_Start** - Orders missing Service_Start_Date__c\n",
    "7. **All_Active_Orders** - Complete list of all active orders\n",
    "\n",
    "---\n",
    "**Created:** December 11, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: C:\\Users\\vjero\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe\n",
      "Pandas: 2.2.3\n",
      "‚úÖ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# === SETUP & IMPORTS ===\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "from simple_salesforce import Salesforce\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(f\"Python: {sys.executable}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Configuration loaded\n",
      "   Output: es_orders_data_quality_20251211_185836.xlsx\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "\n",
    "# ES (Source) Credentials\n",
    "ES_USERNAME = \"sfdcapi@everstream.net\"\n",
    "ES_PASSWORD = \"pV4CAxns8DQtJsBq!\"\n",
    "ES_TOKEN = \"r1uoYiusK19RbrflARydi86TA\"\n",
    "ES_DOMAIN = \"login\"  # or 'login' for production\n",
    "\n",
    "\n",
    "# Active Status Filter\n",
    "ACTIVE_STATUSES = [\"Activated\", \"Suspended (Late Payment)\", \"Disconnect in Progress\"]\n",
    "\n",
    "# Output settings\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_FILE = f\"es_orders_data_quality_{TIMESTAMP}.xlsx\"\n",
    "\n",
    "print(\"üìã Configuration loaded\")\n",
    "print(f\"   Output: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Connecting to ES Salesforce...\n",
      "‚úÖ Connected to ES: everstream.my.salesforce.com\n"
     ]
    }
   ],
   "source": [
    "# === CONNECT TO ES SALESFORCE ===\n",
    "\n",
    "print(\"üîå Connecting to ES Salesforce...\")\n",
    "es_sf = Salesforce(\n",
    "    username=ES_USERNAME,\n",
    "    password=ES_PASSWORD,\n",
    "    security_token=ES_TOKEN,\n",
    "    domain=ES_DOMAIN,\n",
    ")\n",
    "print(f\"‚úÖ Connected to ES: {es_sf.sf_instance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Querying ALL active Orders (this may take a moment)...\n",
      "\n",
      "‚úÖ Retrieved 18,055 active Orders\n",
      "\n",
      "=== Status Breakdown ===\n",
      "Status\n",
      "Activated                   17702\n",
      "Disconnect in Progress        348\n",
      "Suspended (Late Payment)        5\n"
     ]
    }
   ],
   "source": [
    "# === QUERY ALL ACTIVE ORDERS ===\n",
    "\n",
    "print(\"üìä Querying ALL active Orders (this may take a moment)...\")\n",
    "\n",
    "# Build status filter\n",
    "status_filter = \"','\".join(ACTIVE_STATUSES)\n",
    "\n",
    "# Query all fields we need for analysis and migration\n",
    "orders_query = f\"\"\"\n",
    "SELECT \n",
    "    Id, \n",
    "    Name,\n",
    "    Service_ID__c,\n",
    "    Status,\n",
    "    AccountId,\n",
    "    Account.Name,\n",
    "    Billing_Invoice__c,\n",
    "    Address_A__c,\n",
    "    Address_Z__c,\n",
    "    Node__c,\n",
    "    OpportunityId,\n",
    "    Service_Start_Date__c,\n",
    "    Service_End_Date__c,\n",
    "    Service_Provided__c,\n",
    "    SOF_MRC__c,\n",
    "    OSS_Service_ID__c,\n",
    "    Vendor_Circuit_ID__c,\n",
    "    Primary_Product_Family__c,\n",
    "    Primary_Product_Name__c,\n",
    "    CreatedDate,\n",
    "    LastModifiedDate\n",
    "FROM Order\n",
    "WHERE Status IN ('{status_filter}')\n",
    "ORDER BY Service_ID__c\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = es_sf.query_all(orders_query)\n",
    "    orders_df = pd.DataFrame(result[\"records\"])\n",
    "\n",
    "    # Flatten Account.Name\n",
    "    if \"Account\" in orders_df.columns:\n",
    "        orders_df[\"Account_Name\"] = orders_df[\"Account\"].apply(\n",
    "            lambda x: x.get(\"Name\") if isinstance(x, dict) else None\n",
    "        )\n",
    "        orders_df = orders_df.drop(columns=[\"Account\", \"attributes\"], errors=\"ignore\")\n",
    "    else:\n",
    "        orders_df = orders_df.drop(columns=[\"attributes\"], errors=\"ignore\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Retrieved {len(orders_df):,} active Orders\")\n",
    "    print(f\"\\n=== Status Breakdown ===\")\n",
    "    print(orders_df[\"Status\"].value_counts().to_string())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Query error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Categorizing Orders by data issues...\n",
      "\n",
      "=== Data Quality Summary ===\n",
      "   Total Active Orders:        18,055\n",
      "   ‚úÖ Ready to Migrate:        14,433\n",
      "   ‚ùå NOT Ready (has issues):  3,622\n",
      "\n",
      "=== Issue Breakdown ===\n",
      "   ‚ö†Ô∏è  Missing BAN (CRITICAL):   3,595\n",
      "   ‚ö†Ô∏è  Missing A Location:       222\n",
      "   ‚ö†Ô∏è  Missing Z Location:       0\n",
      "   ‚ÑπÔ∏è  Missing Node:             15,360\n",
      "   ‚ÑπÔ∏è  Missing Service Start:    9,105\n"
     ]
    }
   ],
   "source": [
    "# === CATEGORIZE ORDERS BY DATA ISSUES ===\n",
    "\n",
    "print(\"üîç Categorizing Orders by data issues...\")\n",
    "\n",
    "# Create issue flags\n",
    "orders_df[\"Missing_BAN\"] = orders_df[\"Billing_Invoice__c\"].isna()\n",
    "orders_df[\"Missing_A_Location\"] = orders_df[\"Address_A__c\"].isna()\n",
    "orders_df[\"Missing_Z_Location\"] = orders_df[\"Address_Z__c\"].isna()\n",
    "orders_df[\"Missing_Node\"] = orders_df[\"Node__c\"].isna()\n",
    "orders_df[\"Missing_Service_Start\"] = orders_df[\"Service_Start_Date__c\"].isna()\n",
    "orders_df[\"Missing_Opportunity\"] = orders_df[\"OpportunityId\"].isna()\n",
    "\n",
    "# Calculate issue count per order\n",
    "issue_cols = [\n",
    "    \"Missing_BAN\",\n",
    "    \"Missing_A_Location\",\n",
    "    \"Missing_Z_Location\",\n",
    "    \"Missing_Node\",\n",
    "    \"Missing_Service_Start\",\n",
    "]\n",
    "orders_df[\"Issue_Count\"] = orders_df[issue_cols].sum(axis=1)\n",
    "\n",
    "# Determine if ready to migrate (has BAN and A_Location at minimum)\n",
    "orders_df[\"Ready_To_Migrate\"] = (\n",
    "    ~orders_df[\"Missing_BAN\"] & ~orders_df[\"Missing_A_Location\"]\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== Data Quality Summary ===\")\n",
    "print(f\"   Total Active Orders:        {len(orders_df):,}\")\n",
    "print(f\"   ‚úÖ Ready to Migrate:        {orders_df['Ready_To_Migrate'].sum():,}\")\n",
    "print(f\"   ‚ùå NOT Ready (has issues):  {(~orders_df['Ready_To_Migrate']).sum():,}\")\n",
    "\n",
    "print(\"\\n=== Issue Breakdown ===\")\n",
    "print(f\"   ‚ö†Ô∏è  Missing BAN (CRITICAL):   {orders_df['Missing_BAN'].sum():,}\")\n",
    "print(f\"   ‚ö†Ô∏è  Missing A Location:       {orders_df['Missing_A_Location'].sum():,}\")\n",
    "print(f\"   ‚ö†Ô∏è  Missing Z Location:       {orders_df['Missing_Z_Location'].sum():,}\")\n",
    "print(f\"   ‚ÑπÔ∏è  Missing Node:             {orders_df['Missing_Node'].sum():,}\")\n",
    "print(f\"   ‚ÑπÔ∏è  Missing Service Start:    {orders_df['Missing_Service_Start'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Creating category dataframes...\n",
      "   ‚úÖ Ready_To_Migrate: 14,433 orders\n",
      "   ‚ö†Ô∏è  Missing_BAN: 3,595 orders\n",
      "   ‚ö†Ô∏è  Missing_A_Location: 222 orders\n",
      "   ‚ÑπÔ∏è  Missing_Node: 15,360 orders\n",
      "   ‚ÑπÔ∏è  Missing_Service_Start: 9,105 orders\n"
     ]
    }
   ],
   "source": [
    "# === CREATE CATEGORY DATAFRAMES ===\n",
    "\n",
    "print(\"üìÅ Creating category dataframes...\")\n",
    "\n",
    "# Columns to include in output (excluding flags)\n",
    "output_cols = [\n",
    "    \"Id\",\n",
    "    \"Service_ID__c\",\n",
    "    \"Status\",\n",
    "    \"Account_Name\",\n",
    "    \"AccountId\",\n",
    "    \"Billing_Invoice__c\",\n",
    "    \"Address_A__c\",\n",
    "    \"Address_Z__c\",\n",
    "    \"Node__c\",\n",
    "    \"OpportunityId\",\n",
    "    \"Service_Start_Date__c\",\n",
    "    \"Service_End_Date__c\",\n",
    "    \"Service_Provided__c\",\n",
    "    \"SOF_MRC__c\",\n",
    "    \"OSS_Service_ID__c\",\n",
    "    \"Primary_Product_Family__c\",\n",
    "    \"Primary_Product_Name__c\",\n",
    "    \"Issue_Count\",\n",
    "    \"Ready_To_Migrate\",\n",
    "]\n",
    "\n",
    "# Filter columns that exist\n",
    "output_cols = [c for c in output_cols if c in orders_df.columns]\n",
    "\n",
    "# Ready to migrate\n",
    "ready_df = orders_df[orders_df[\"Ready_To_Migrate\"]][output_cols].copy()\n",
    "print(f\"   ‚úÖ Ready_To_Migrate: {len(ready_df):,} orders\")\n",
    "\n",
    "# Missing BAN (CRITICAL)\n",
    "missing_ban_df = orders_df[orders_df[\"Missing_BAN\"]][output_cols].copy()\n",
    "print(f\"   ‚ö†Ô∏è  Missing_BAN: {len(missing_ban_df):,} orders\")\n",
    "\n",
    "# Missing A Location\n",
    "missing_aloc_df = orders_df[orders_df[\"Missing_A_Location\"]][output_cols].copy()\n",
    "print(f\"   ‚ö†Ô∏è  Missing_A_Location: {len(missing_aloc_df):,} orders\")\n",
    "\n",
    "# Missing Node (for reference - can be post-migration)\n",
    "missing_node_df = orders_df[orders_df[\"Missing_Node\"]][output_cols].copy()\n",
    "print(f\"   ‚ÑπÔ∏è  Missing_Node: {len(missing_node_df):,} orders\")\n",
    "\n",
    "# Missing Service Start Date\n",
    "missing_start_df = orders_df[orders_df[\"Missing_Service_Start\"]][output_cols].copy()\n",
    "print(f\"   ‚ÑπÔ∏è  Missing_Service_Start: {len(missing_start_df):,} orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Analyzing Orders missing BAN (Billing_Invoice__c)...\n",
      "\n",
      "=== Account Distribution (Missing BAN) ===\n",
      "Account_Name\n",
      "INTERNAL EVERSTREAM (Network Expansion Build-Out)        1467\n",
      "INTERNAL EVERSTREAM (RELO & EMERGENCY REPAIR)             505\n",
      "INTERNAL EVERSTREAM NETWORK RESOURCES (DO NOT DELETE)     500\n",
      "INTERNAL EVS (Vendor Orders)                              198\n",
      "T-Mobile Small Cell                                       111\n",
      "INTERNAL EVERSTREAM (MTU BUILDINGS)                       110\n",
      "Internal Everstream Network Resources Michigan             92\n",
      "T-Mobile                                                   76\n",
      "The Lincoln Electric Company                               35\n",
      "Sherwin Williams                                           33\n",
      "City of Lakewood                                           28\n",
      "US Cellular - Network Engineering                          27\n",
      "AT&T Mobility (PEG) (UNC)                                  27\n",
      "ACD                                                        21\n",
      "DISH Wireless                                              19\n",
      "Grosse Pointe Public School System                         18\n",
      "Michigan Dept of Corrections DTMB Telecommunications       18\n",
      "Rocket Limited Partnership                                 15\n",
      "LAKEWOOD CITY SCHOOL DISTRICT                              13\n",
      "Verizon Wireless - Customer                                 9\n",
      "\n",
      "=== Product Family Distribution (Missing BAN) ===\n",
      "Primary_Product_Family__c\n",
      "Dark Fiber (DFBR)                           268\n",
      "Network-to-Network Interface (NNIS)         177\n",
      "Dedicated Internet Access (DIAS)             74\n",
      "Collocation (COLO)                           67\n",
      "Point-to-Point (PTPS)                        66\n",
      "Dedicated DWDM (DWDM)                        66\n",
      "Hosted Voice (VOIC)                          38\n",
      "Managed Wave (MWAV)                          12\n",
      "Virtual Dedicated Internet Access (VDIA)      9\n",
      "SS7 (VOIC)                                    9\n",
      "\n",
      "üìå Possibly Internal/Test accounts: 2,883 (80.2%)\n"
     ]
    }
   ],
   "source": [
    "# === ANALYZE MISSING BAN ORDERS ===\n",
    "\n",
    "print(\"\\nüîç Analyzing Orders missing BAN (Billing_Invoice__c)...\")\n",
    "\n",
    "if len(missing_ban_df) > 0:\n",
    "    # Check if they have Account names that might give us clues\n",
    "    print(\"\\n=== Account Distribution (Missing BAN) ===\")\n",
    "    account_dist = missing_ban_df[\"Account_Name\"].value_counts().head(20)\n",
    "    print(account_dist.to_string())\n",
    "\n",
    "    # Check Product Family distribution\n",
    "    if \"Primary_Product_Family__c\" in missing_ban_df.columns:\n",
    "        print(\"\\n=== Product Family Distribution (Missing BAN) ===\")\n",
    "        prod_dist = missing_ban_df[\"Primary_Product_Family__c\"].value_counts().head(10)\n",
    "        print(prod_dist.to_string())\n",
    "\n",
    "    # Check if there's a pattern (internal accounts, etc.)\n",
    "    internal_keywords = [\"INTERNAL\", \"TEST\", \"DEMO\", \"SANDBOX\"]\n",
    "    internal_mask = (\n",
    "        missing_ban_df[\"Account_Name\"]\n",
    "        .str.upper()\n",
    "        .str.contains(\"|\".join(internal_keywords), na=False)\n",
    "    )\n",
    "    internal_count = internal_mask.sum()\n",
    "    print(\n",
    "        f\"\\nüìå Possibly Internal/Test accounts: {internal_count:,} ({internal_count/len(missing_ban_df)*100:.1f}%)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úÖ No orders missing BAN!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating summary...\n",
      "                Category  Count Percentage                                               Action\n",
      "     Total Active Orders  18055       100%                                                  N/A\n",
      "      ‚úÖ Ready to Migrate  14433      79.9%                               Proceed with migration\n",
      "‚ùå Missing BAN (CRITICAL)   3595      19.9% MUST FIX - Cannot migrate without Billing_Invoice__c\n",
      "   ‚ö†Ô∏è Missing A Location    222       1.2%      Should fix - Required for A_Location__c mapping\n",
      "         ‚ÑπÔ∏è Missing Node  15360      85.1%   Can fix post-migration - A_Node__c is not critical\n",
      "‚ÑπÔ∏è Missing Service Start   9105      50.4%                 Review - May need for Active_Date__c\n"
     ]
    }
   ],
   "source": [
    "# === CREATE SUMMARY DATAFRAME ===\n",
    "\n",
    "print(\"üìä Creating summary...\")\n",
    "\n",
    "summary_data = [\n",
    "    {\n",
    "        \"Category\": \"Total Active Orders\",\n",
    "        \"Count\": len(orders_df),\n",
    "        \"Percentage\": \"100%\",\n",
    "        \"Action\": \"N/A\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"‚úÖ Ready to Migrate\",\n",
    "        \"Count\": len(ready_df),\n",
    "        \"Percentage\": f\"{len(ready_df)/len(orders_df)*100:.1f}%\",\n",
    "        \"Action\": \"Proceed with migration\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"‚ùå Missing BAN (CRITICAL)\",\n",
    "        \"Count\": len(missing_ban_df),\n",
    "        \"Percentage\": f\"{len(missing_ban_df)/len(orders_df)*100:.1f}%\",\n",
    "        \"Action\": \"MUST FIX - Cannot migrate without Billing_Invoice__c\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"‚ö†Ô∏è Missing A Location\",\n",
    "        \"Count\": len(missing_aloc_df),\n",
    "        \"Percentage\": f\"{len(missing_aloc_df)/len(orders_df)*100:.1f}%\",\n",
    "        \"Action\": \"Should fix - Required for A_Location__c mapping\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"‚ÑπÔ∏è Missing Node\",\n",
    "        \"Count\": len(missing_node_df),\n",
    "        \"Percentage\": f\"{len(missing_node_df)/len(orders_df)*100:.1f}%\",\n",
    "        \"Action\": \"Can fix post-migration - A_Node__c is not critical\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"‚ÑπÔ∏è Missing Service Start\",\n",
    "        \"Count\": len(missing_start_df),\n",
    "        \"Percentage\": f\"{len(missing_start_df)/len(orders_df)*100:.1f}%\",\n",
    "        \"Action\": \"Review - May need for Active_Date__c\",\n",
    "    },\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Exporting to es_orders_data_quality_20251211_185836.xlsx...\n",
      "\n",
      "‚úÖ Export complete: es_orders_data_quality_20251211_185836.xlsx\n",
      "\n",
      "=== Sheets Created ===\n",
      "   1. Summary - Overview of data quality\n",
      "   2. Ready_To_Migrate - 14,433 orders ready\n",
      "   3. Missing_BAN_CRITICAL - 3,595 orders (MUST FIX)\n",
      "   4. Missing_A_Location - 222 orders\n",
      "   5. Missing_Node - 15,360 orders (post-migration)\n",
      "   6. Missing_Service_Start - 9,105 orders\n",
      "   7. All_Active_Orders - 18,055 orders (complete list)\n"
     ]
    }
   ],
   "source": [
    "# === EXPORT TO EXCEL ===\n",
    "\n",
    "print(f\"\\nüìÅ Exporting to {OUTPUT_FILE}...\")\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\") as writer:\n",
    "\n",
    "    # Summary\n",
    "    summary_df.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
    "\n",
    "    # Ready to Migrate\n",
    "    ready_df.to_excel(writer, sheet_name=\"Ready_To_Migrate\", index=False)\n",
    "\n",
    "    # Missing BAN (CRITICAL)\n",
    "    missing_ban_df.to_excel(writer, sheet_name=\"Missing_BAN_CRITICAL\", index=False)\n",
    "\n",
    "    # Missing A Location\n",
    "    missing_aloc_df.to_excel(writer, sheet_name=\"Missing_A_Location\", index=False)\n",
    "\n",
    "    # Missing Node (reference)\n",
    "    missing_node_df.to_excel(writer, sheet_name=\"Missing_Node\", index=False)\n",
    "\n",
    "    # Missing Service Start\n",
    "    missing_start_df.to_excel(writer, sheet_name=\"Missing_Service_Start\", index=False)\n",
    "\n",
    "    # All Active Orders (complete list)\n",
    "    orders_df[output_cols].to_excel(writer, sheet_name=\"All_Active_Orders\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Export complete: {OUTPUT_FILE}\")\n",
    "print(f\"\\n=== Sheets Created ===\")\n",
    "print(f\"   1. Summary - Overview of data quality\")\n",
    "print(f\"   2. Ready_To_Migrate - {len(ready_df):,} orders ready\")\n",
    "print(f\"   3. Missing_BAN_CRITICAL - {len(missing_ban_df):,} orders (MUST FIX)\")\n",
    "print(f\"   4. Missing_A_Location - {len(missing_aloc_df):,} orders\")\n",
    "print(f\"   5. Missing_Node - {len(missing_node_df):,} orders (post-migration)\")\n",
    "print(f\"   6. Missing_Service_Start - {len(missing_start_df):,} orders\")\n",
    "print(f\"   7. All_Active_Orders - {len(orders_df):,} orders (complete list)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "### Priority 1: Fix Missing BAN (3,451 orders)\n",
    "These orders CANNOT be migrated without `Billing_Invoice__c`.\n",
    "\n",
    "**Options:**\n",
    "1. **Find/Create BANs** - Identify correct Billing_Invoice__c for each order\n",
    "2. **Exclude from migration** - If these are internal/test records\n",
    "3. **Create default BAN** - If business approves a catch-all BAN\n",
    "\n",
    "### Priority 2: Fix Missing A Location (201 orders)\n",
    "These need `Address_A__c` populated for `A_Location__c` mapping.\n",
    "\n",
    "### Priority 3: Review Missing Node (15,811 orders)\n",
    "Can be fixed post-migration since `A_Node__c` is not critical for initial load.\n",
    "\n",
    "### Priority 4: Review Missing Service Start (8,875 orders)\n",
    "May need for `Active_Date__c` - review if these are truly activated services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PLACEHOLDER FOR ADDITIONAL ANALYSIS ===\n",
    "\n",
    "# Add custom queries here as needed\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
