{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES Order Data Quality Analysis\n",
    "\n",
    "This notebook pulls ALL active ES Orders and categorizes them by data issues for remediation.\n",
    "\n",
    "## Filters Applied\n",
    "- **Status Filter:** Activated, Suspended (Late Payment), Disconnect in Progress\n",
    "- **PA Market Exclusion:** Pittsburgh, Harrisburg, Philadelphia, Scranton, Uniti-PA\n",
    "\n",
    "## Output: Excel file with tabs:\n",
    "1. **Summary** - Overall counts and issues\n",
    "2. **Ready_To_Migrate** - Orders with all required fields populated\n",
    "3. **Missing_BAN** - Orders missing Billing_Invoice__c (CRITICAL - cannot migrate)\n",
    "4. **Missing_A_Location** - Orders missing Address_A__c\n",
    "5. **Missing_Node** - Orders missing Node__c (can be post-migration)\n",
    "6. **Missing_Service_Start** - Orders missing Service_Start_Date__c\n",
    "7. **EXCLUDED_PA_Market** - Orders excluded due to PA market\n",
    "8. **All_Active_Orders** - Complete list of all active orders (after PA filter)\n",
    "\n",
    "---\n",
    "**Created:** December 11, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: C:\\Users\\vjero\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe\n",
      "Pandas: 2.2.3\n",
      "âœ… Imports successful\n"
     ]
    }
   ],
   "source": [
    "# === SETUP & IMPORTS ===\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "from simple_salesforce import Salesforce\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(f\"Python: {sys.executable}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Configuration loaded\n",
      "   Active Statuses: ['Activated', 'Suspended (Late Payment)', 'Disconnect in Progress']\n",
      "   PA Markets to EXCLUDE: ['Pittsburgh', 'Harrisburg', 'Philadelphia', 'Scranton', 'Uniti-PA']\n",
      "   Output: es_orders_data_quality_20251230_092815.xlsx\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "\n",
    "# ES (Source) Credentials\n",
    "ES_USERNAME = \"sfdcapi@everstream.net\"\n",
    "ES_PASSWORD = \"pV4CAxns8DQtJsBq!\"\n",
    "ES_TOKEN = \"r1uoYiusK19RbrflARydi86TA\"\n",
    "ES_DOMAIN = \"login\"  # or 'login' for production\n",
    "\n",
    "# Active Status Filter\n",
    "ACTIVE_STATUSES = [\"Activated\", \"Suspended (Late Payment)\", \"Disconnect in Progress\"]\n",
    "\n",
    "# PA Market Filter (EXCLUDE these values from Dimension_4_Market__c)\n",
    "PA_MARKETS_TO_EXCLUDE = [\n",
    "    \"Pittsburgh\",\n",
    "    \"Harrisburg\",\n",
    "    \"Philadelphia\",\n",
    "    \"Scranton\",\n",
    "    \"Uniti-PA\",\n",
    "]\n",
    "\n",
    "# Output settings\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_FILE = f\"es_orders_data_quality_{TIMESTAMP}.xlsx\"\n",
    "\n",
    "print(\"ðŸ“‹ Configuration loaded\")\n",
    "print(f\"   Active Statuses: {ACTIVE_STATUSES}\")\n",
    "print(f\"   PA Markets to EXCLUDE: {PA_MARKETS_TO_EXCLUDE}\")\n",
    "print(f\"   Output: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Œ Connecting to ES Salesforce...\n",
      "âœ… Connected to ES: everstream.my.salesforce.com\n"
     ]
    }
   ],
   "source": [
    "# === CONNECT TO ES SALESFORCE ===\n",
    "\n",
    "print(\"ðŸ”Œ Connecting to ES Salesforce...\")\n",
    "es_sf = Salesforce(\n",
    "    username=ES_USERNAME,\n",
    "    password=ES_PASSWORD,\n",
    "    security_token=ES_TOKEN,\n",
    "    domain=ES_DOMAIN,\n",
    ")\n",
    "print(f\"âœ… Connected to ES: {es_sf.sf_instance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Querying ALL active Orders (this may take a moment)...\n",
      "\n",
      "âœ… Retrieved 17,947 active Orders\n",
      "\n",
      "=== Status Breakdown ===\n",
      "Status\n",
      "Activated                   17674\n",
      "Disconnect in Progress        272\n",
      "Suspended (Late Payment)        1\n"
     ]
    }
   ],
   "source": [
    "# === QUERY ALL ACTIVE ORDERS ===\n",
    "\n",
    "print(\"ðŸ“Š Querying ALL active Orders (this may take a moment)...\")\n",
    "\n",
    "# Build status filter\n",
    "status_filter = \"','\".join(ACTIVE_STATUSES)\n",
    "\n",
    "# Query all fields we need for analysis and migration\n",
    "orders_query = f\"\"\"\n",
    "SELECT \n",
    "    Id, \n",
    "    Name,\n",
    "    Service_ID__c,\n",
    "    Status,\n",
    "    AccountId,\n",
    "    Account.Name,\n",
    "    Billing_Invoice__c,\n",
    "    Address_A__c,\n",
    "    Address_Z__c,\n",
    "    Node__c,\n",
    "    OpportunityId,\n",
    "    Service_Start_Date__c,\n",
    "    Service_End_Date__c,\n",
    "    Service_Provided__c,\n",
    "    SOF_MRC__c,\n",
    "    OSS_Service_ID__c,\n",
    "    OSS_Order__c,\n",
    "    Vendor_Circuit_ID__c,\n",
    "    Primary_Product_Family__c,\n",
    "    Primary_Product_Name__c,\n",
    "    Dimension_4_Market__c,\n",
    "    CreatedDate,\n",
    "    LastModifiedDate\n",
    "FROM Order\n",
    "WHERE Status IN ('{status_filter}')\n",
    "ORDER BY Service_ID__c\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = es_sf.query_all(orders_query)\n",
    "    orders_df = pd.DataFrame(result[\"records\"])\n",
    "\n",
    "    # Flatten Account.Name\n",
    "    if \"Account\" in orders_df.columns:\n",
    "        orders_df[\"Account_Name\"] = orders_df[\"Account\"].apply(\n",
    "            lambda x: x.get(\"Name\") if isinstance(x, dict) else None\n",
    "        )\n",
    "        orders_df = orders_df.drop(columns=[\"Account\", \"attributes\"], errors=\"ignore\")\n",
    "    else:\n",
    "        orders_df = orders_df.drop(columns=[\"attributes\"], errors=\"ignore\")\n",
    "\n",
    "    print(f\"\\nâœ… Retrieved {len(orders_df):,} active Orders\")\n",
    "    print(f\"\\n=== Status Breakdown ===\")\n",
    "    print(orders_df[\"Status\"].value_counts().to_string())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Query error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Filtering out PA Market orders...\n",
      "\n",
      "=== PA Market Filter Results ===\n",
      "   Orders EXCLUDED (PA Market): 1,054\n",
      "   Orders REMAINING (to migrate): 16,893\n",
      "\n",
      "=== PA Market Breakdown ===\n",
      "Dimension_4_Market__c\n",
      "Uniti-PA        577\n",
      "Philadelphia    283\n",
      "Pittsburgh       90\n",
      "Scranton         75\n",
      "Harrisburg       29\n",
      "\n",
      "=== Remaining Orders by Market ===\n",
      "Dimension_4_Market__c\n",
      "Cleveland                   5963\n",
      "Michigan                    3179\n",
      "Detroit                     2006\n",
      "Indiana                     1532\n",
      "Wisconsin                   1185\n",
      "Columbus                    1162\n",
      "Illinois                     971\n",
      "Wisconsin Expansion          523\n",
      "Missouri                     299\n",
      "Kentucky                      64\n",
      "None                           7\n",
      "Multi - Expansion Market       2\n"
     ]
    }
   ],
   "source": [
    "# === FILTER OUT PA MARKET ===\n",
    "\n",
    "print(\"ðŸ” Filtering out PA Market orders...\")\n",
    "\n",
    "# Identify PA market orders\n",
    "pa_market_mask = orders_df[\"Dimension_4_Market__c\"].isin(PA_MARKETS_TO_EXCLUDE)\n",
    "pa_orders_df = orders_df[pa_market_mask].copy()\n",
    "orders_df = orders_df[~pa_market_mask].copy()\n",
    "\n",
    "print(f\"\\n=== PA Market Filter Results ===\")\n",
    "print(f\"   Orders EXCLUDED (PA Market): {len(pa_orders_df):,}\")\n",
    "print(f\"   Orders REMAINING (to migrate): {len(orders_df):,}\")\n",
    "\n",
    "if len(pa_orders_df) > 0:\n",
    "    print(f\"\\n=== PA Market Breakdown ===\")\n",
    "    print(pa_orders_df[\"Dimension_4_Market__c\"].value_counts().to_string())\n",
    "\n",
    "# Also show market distribution for remaining orders\n",
    "print(f\"\\n=== Remaining Orders by Market ===\")\n",
    "print(\n",
    "    orders_df[\"Dimension_4_Market__c\"].value_counts(dropna=False).head(15).to_string()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Categorizing Orders by data issues...\n",
      "\n",
      "=== Data Quality Summary ===\n",
      "   Total Active Orders:        16,893\n",
      "   âœ… Ready to Migrate:        13,433\n",
      "   âŒ NOT Ready (has issues):  3,460\n",
      "\n",
      "=== Issue Breakdown ===\n",
      "   âš ï¸  Missing BAN (CRITICAL):   3,447\n",
      "   âš ï¸  Missing A Location:       209\n",
      "   âš ï¸  Missing Z Location:       0\n",
      "   â„¹ï¸  Missing Node:             14,803\n",
      "   â„¹ï¸  Missing Service Start:    8,589\n"
     ]
    }
   ],
   "source": [
    "# === CATEGORIZE ORDERS BY DATA ISSUES ===\n",
    "\n",
    "print(\"ðŸ” Categorizing Orders by data issues...\")\n",
    "\n",
    "# Create issue flags\n",
    "orders_df[\"Missing_BAN\"] = orders_df[\"Billing_Invoice__c\"].isna()\n",
    "orders_df[\"Missing_A_Location\"] = orders_df[\"Address_A__c\"].isna()\n",
    "orders_df[\"Missing_Z_Location\"] = orders_df[\"Address_Z__c\"].isna()\n",
    "orders_df[\"Missing_Node\"] = orders_df[\"Node__c\"].isna()\n",
    "orders_df[\"Missing_Service_Start\"] = orders_df[\"Service_Start_Date__c\"].isna()\n",
    "orders_df[\"Missing_Opportunity\"] = orders_df[\"OpportunityId\"].isna()\n",
    "\n",
    "# Calculate issue count per order\n",
    "issue_cols = [\n",
    "    \"Missing_BAN\",\n",
    "    \"Missing_A_Location\",\n",
    "    \"Missing_Z_Location\",\n",
    "    \"Missing_Node\",\n",
    "    \"Missing_Service_Start\",\n",
    "]\n",
    "orders_df[\"Issue_Count\"] = orders_df[issue_cols].sum(axis=1)\n",
    "\n",
    "# Determine if ready to migrate (has BAN and A_Location at minimum)\n",
    "orders_df[\"Ready_To_Migrate\"] = (\n",
    "    ~orders_df[\"Missing_BAN\"] & ~orders_df[\"Missing_A_Location\"]\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== Data Quality Summary ===\")\n",
    "print(f\"   Total Active Orders:        {len(orders_df):,}\")\n",
    "print(f\"   âœ… Ready to Migrate:        {orders_df['Ready_To_Migrate'].sum():,}\")\n",
    "print(f\"   âŒ NOT Ready (has issues):  {(~orders_df['Ready_To_Migrate']).sum():,}\")\n",
    "\n",
    "print(\"\\n=== Issue Breakdown ===\")\n",
    "print(f\"   âš ï¸  Missing BAN (CRITICAL):   {orders_df['Missing_BAN'].sum():,}\")\n",
    "print(f\"   âš ï¸  Missing A Location:       {orders_df['Missing_A_Location'].sum():,}\")\n",
    "print(f\"   âš ï¸  Missing Z Location:       {orders_df['Missing_Z_Location'].sum():,}\")\n",
    "print(f\"   â„¹ï¸  Missing Node:             {orders_df['Missing_Node'].sum():,}\")\n",
    "print(f\"   â„¹ï¸  Missing Service Start:    {orders_df['Missing_Service_Start'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Creating category dataframes...\n",
      "   âœ… Ready_To_Migrate: 13,433 orders\n",
      "   âš ï¸  Missing_BAN: 3,447 orders\n",
      "   âš ï¸  Missing_A_Location: 209 orders\n",
      "   â„¹ï¸  Missing_Node: 14,803 orders\n",
      "   â„¹ï¸  Missing_Service_Start: 8,589 orders\n"
     ]
    }
   ],
   "source": [
    "# === CREATE CATEGORY DATAFRAMES ===\n",
    "\n",
    "print(\"ðŸ“ Creating category dataframes...\")\n",
    "\n",
    "# Columns to include in output (excluding flags)\n",
    "output_cols = [\n",
    "    \"Id\",\n",
    "    \"Service_ID__c\",\n",
    "    \"Status\",\n",
    "    \"Account_Name\",\n",
    "    \"AccountId\",\n",
    "    \"Billing_Invoice__c\",\n",
    "    \"Address_A__c\",\n",
    "    \"Address_Z__c\",\n",
    "    \"Node__c\",\n",
    "    \"OpportunityId\",\n",
    "    \"Service_Start_Date__c\",\n",
    "    \"Service_End_Date__c\",\n",
    "    \"Service_Provided__c\",\n",
    "    \"SOF_MRC__c\",\n",
    "    \"OSS_Service_ID__c\",\n",
    "    \"OSS_Order__c\",\n",
    "    \"Primary_Product_Family__c\",\n",
    "    \"Primary_Product_Name__c\",\n",
    "    \"Dimension_4_Market__c\",\n",
    "    \"Issue_Count\",\n",
    "    \"Ready_To_Migrate\",\n",
    "]\n",
    "\n",
    "# Filter columns that exist\n",
    "output_cols = [c for c in output_cols if c in orders_df.columns]\n",
    "\n",
    "# Ready to migrate\n",
    "ready_df = orders_df[orders_df[\"Ready_To_Migrate\"]][output_cols].copy()\n",
    "print(f\"   âœ… Ready_To_Migrate: {len(ready_df):,} orders\")\n",
    "\n",
    "# Missing BAN (CRITICAL)\n",
    "missing_ban_df = orders_df[orders_df[\"Missing_BAN\"]][output_cols].copy()\n",
    "print(f\"   âš ï¸  Missing_BAN: {len(missing_ban_df):,} orders\")\n",
    "\n",
    "# Missing A Location\n",
    "missing_aloc_df = orders_df[orders_df[\"Missing_A_Location\"]][output_cols].copy()\n",
    "print(f\"   âš ï¸  Missing_A_Location: {len(missing_aloc_df):,} orders\")\n",
    "\n",
    "# Missing Node (for reference - can be post-migration)\n",
    "missing_node_df = orders_df[orders_df[\"Missing_Node\"]][output_cols].copy()\n",
    "print(f\"   â„¹ï¸  Missing_Node: {len(missing_node_df):,} orders\")\n",
    "\n",
    "# Missing Service Start Date\n",
    "missing_start_df = orders_df[orders_df[\"Missing_Service_Start\"]][output_cols].copy()\n",
    "print(f\"   â„¹ï¸  Missing_Service_Start: {len(missing_start_df):,} orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Analyzing Orders missing BAN (Billing_Invoice__c)...\n",
      "\n",
      "=== Account Distribution (Missing BAN) ===\n",
      "Account_Name\n",
      "INTERNAL EVERSTREAM (Network Expansion Build-Out)        1423\n",
      "INTERNAL EVERSTREAM (RELO & EMERGENCY REPAIR)             494\n",
      "INTERNAL EVERSTREAM NETWORK RESOURCES (DO NOT DELETE)     483\n",
      "INTERNAL EVS (Vendor Orders)                              186\n",
      "T-Mobile Small Cell                                       111\n",
      "INTERNAL EVERSTREAM (MTU BUILDINGS)                       108\n",
      "Internal Everstream Network Resources Michigan             92\n",
      "T-Mobile                                                   69\n",
      "The Lincoln Electric Company                               35\n",
      "Sherwin Williams                                           33\n",
      "City of Lakewood                                           28\n",
      "US Cellular - Network Engineering                          27\n",
      "ACD                                                        21\n",
      "DISH Wireless                                              20\n",
      "Michigan Dept of Corrections DTMB Telecommunications       18\n",
      "Grosse Pointe Public School System                         18\n",
      "Rocket Limited Partnership                                 16\n",
      "LAKEWOOD CITY SCHOOL DISTRICT                              13\n",
      "Verizon Wireless - Customer                                 7\n",
      "INTERNAL EVERSTREAM (CONSUMABLES)                           7\n",
      "\n",
      "=== Product Family Distribution (Missing BAN) ===\n",
      "Primary_Product_Family__c\n",
      "Dark Fiber (DFBR)                           263\n",
      "Network-to-Network Interface (NNIS)         141\n",
      "Dedicated Internet Access (DIAS)             72\n",
      "Dedicated DWDM (DWDM)                        66\n",
      "Point-to-Point (PTPS)                        64\n",
      "Collocation (COLO)                           50\n",
      "Hosted Voice (VOIC)                          38\n",
      "SS7 (VOIC)                                    9\n",
      "Managed Wave (MWAV)                           9\n",
      "Virtual Dedicated Internet Access (VDIA)      9\n",
      "\n",
      "ðŸ“Œ Possibly Internal/Test accounts: 2,796 (81.1%)\n"
     ]
    }
   ],
   "source": [
    "# === ANALYZE MISSING BAN ORDERS ===\n",
    "\n",
    "print(\"\\nðŸ” Analyzing Orders missing BAN (Billing_Invoice__c)...\")\n",
    "\n",
    "if len(missing_ban_df) > 0:\n",
    "    # Check if they have Account names that might give us clues\n",
    "    print(\"\\n=== Account Distribution (Missing BAN) ===\")\n",
    "    account_dist = missing_ban_df[\"Account_Name\"].value_counts().head(20)\n",
    "    print(account_dist.to_string())\n",
    "\n",
    "    # Check Product Family distribution\n",
    "    if \"Primary_Product_Family__c\" in missing_ban_df.columns:\n",
    "        print(\"\\n=== Product Family Distribution (Missing BAN) ===\")\n",
    "        prod_dist = missing_ban_df[\"Primary_Product_Family__c\"].value_counts().head(10)\n",
    "        print(prod_dist.to_string())\n",
    "\n",
    "    # Check if there's a pattern (internal accounts, etc.)\n",
    "    internal_keywords = [\"INTERNAL\", \"TEST\", \"DEMO\", \"SANDBOX\"]\n",
    "    internal_mask = (\n",
    "        missing_ban_df[\"Account_Name\"]\n",
    "        .str.upper()\n",
    "        .str.contains(\"|\".join(internal_keywords), na=False)\n",
    "    )\n",
    "    internal_count = internal_mask.sum()\n",
    "    print(\n",
    "        f\"\\nðŸ“Œ Possibly Internal/Test accounts: {internal_count:,} ({internal_count/len(missing_ban_df)*100:.1f}%)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"âœ… No orders missing BAN!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Creating summary...\n",
      "                                 Category Count Percentage                                                                             Action\n",
      "   Total Active Orders (before PA filter) 17947       100%                                                                                N/A\n",
      "                   ðŸš« EXCLUDED - PA Market  1054       5.9% Excluded from migration (Pittsburgh, Harrisburg, Philadelphia, Scranton, Uniti-PA)\n",
      "                                                                                                                                             \n",
      "Total Orders to Migrate (after PA filter) 16893      94.1%                                                                                N/A\n",
      "                       âœ… Ready to Migrate 13433      79.5%                                                             Proceed with migration\n",
      "                 âŒ Missing BAN (CRITICAL)  3447      20.4%                               MUST FIX - Cannot migrate without Billing_Invoice__c\n",
      "                    âš ï¸ Missing A Location   209       1.2%                                    Should fix - Required for A_Location__c mapping\n",
      "                          â„¹ï¸ Missing Node 14803      87.6%                                 Can fix post-migration - A_Node__c is not critical\n",
      "                 â„¹ï¸ Missing Service Start  8589      50.8%                                               Review - May need for Active_Date__c\n"
     ]
    }
   ],
   "source": [
    "# === CREATE SUMMARY DATAFRAME ===\n",
    "\n",
    "print(\"ðŸ“Š Creating summary...\")\n",
    "\n",
    "total_before_pa_filter = len(orders_df) + len(pa_orders_df)\n",
    "\n",
    "summary_data = [\n",
    "    {\n",
    "        \"Category\": \"Total Active Orders (before PA filter)\",\n",
    "        \"Count\": total_before_pa_filter,\n",
    "        \"Percentage\": \"100%\",\n",
    "        \"Action\": \"N/A\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"ðŸš« EXCLUDED - PA Market\",\n",
    "        \"Count\": len(pa_orders_df),\n",
    "        \"Percentage\": f\"{len(pa_orders_df)/total_before_pa_filter*100:.1f}%\",\n",
    "        \"Action\": \"Excluded from migration (Pittsburgh, Harrisburg, Philadelphia, Scranton, Uniti-PA)\",\n",
    "    },\n",
    "    {\"Category\": \"\", \"Count\": \"\", \"Percentage\": \"\", \"Action\": \"\"},\n",
    "    {\n",
    "        \"Category\": \"Total Orders to Migrate (after PA filter)\",\n",
    "        \"Count\": len(orders_df),\n",
    "        \"Percentage\": f\"{len(orders_df)/total_before_pa_filter*100:.1f}%\",\n",
    "        \"Action\": \"N/A\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"âœ… Ready to Migrate\",\n",
    "        \"Count\": len(ready_df),\n",
    "        \"Percentage\": f\"{len(ready_df)/len(orders_df)*100:.1f}%\",\n",
    "        \"Action\": \"Proceed with migration\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"âŒ Missing BAN (CRITICAL)\",\n",
    "        \"Count\": len(missing_ban_df),\n",
    "        \"Percentage\": f\"{len(missing_ban_df)/len(orders_df)*100:.1f}%\",\n",
    "        \"Action\": \"MUST FIX - Cannot migrate without Billing_Invoice__c\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"âš ï¸ Missing A Location\",\n",
    "        \"Count\": len(missing_aloc_df),\n",
    "        \"Percentage\": f\"{len(missing_aloc_df)/len(orders_df)*100:.1f}%\",\n",
    "        \"Action\": \"Should fix - Required for A_Location__c mapping\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"â„¹ï¸ Missing Node\",\n",
    "        \"Count\": len(missing_node_df),\n",
    "        \"Percentage\": f\"{len(missing_node_df)/len(orders_df)*100:.1f}%\",\n",
    "        \"Action\": \"Can fix post-migration - A_Node__c is not critical\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"â„¹ï¸ Missing Service Start\",\n",
    "        \"Count\": len(missing_start_df),\n",
    "        \"Percentage\": f\"{len(missing_start_df)/len(orders_df)*100:.1f}%\",\n",
    "        \"Action\": \"Review - May need for Active_Date__c\",\n",
    "    },\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Exporting to es_orders_data_quality_20251230_092815.xlsx...\n",
      "\n",
      "âœ… Export complete: es_orders_data_quality_20251230_092815.xlsx\n",
      "\n",
      "=== Sheets Created ===\n",
      "   1. Summary - Overview of data quality\n",
      "   2. Ready_To_Migrate - 13,433 orders ready\n",
      "   3. Missing_BAN_CRITICAL - 3,447 orders (MUST FIX)\n",
      "   4. Missing_A_Location - 209 orders\n",
      "   5. Missing_Node - 14,803 orders (post-migration)\n",
      "   6. Missing_Service_Start - 8,589 orders\n",
      "   7. EXCLUDED_PA_Market - 1,054 orders (not migrating)\n",
      "   8. All_Active_Orders - 16,893 orders (to migrate)\n"
     ]
    }
   ],
   "source": [
    "# === EXPORT TO EXCEL ===\n",
    "\n",
    "print(f\"\\nðŸ“ Exporting to {OUTPUT_FILE}...\")\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\") as writer:\n",
    "\n",
    "    # Summary\n",
    "    summary_df.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
    "\n",
    "    # Ready to Migrate\n",
    "    ready_df.to_excel(writer, sheet_name=\"Ready_To_Migrate\", index=False)\n",
    "\n",
    "    # Missing BAN (CRITICAL)\n",
    "    missing_ban_df.to_excel(writer, sheet_name=\"Missing_BAN_CRITICAL\", index=False)\n",
    "\n",
    "    # Missing A Location\n",
    "    missing_aloc_df.to_excel(writer, sheet_name=\"Missing_A_Location\", index=False)\n",
    "\n",
    "    # Missing Node (reference)\n",
    "    missing_node_df.to_excel(writer, sheet_name=\"Missing_Node\", index=False)\n",
    "\n",
    "    # Missing Service Start\n",
    "    missing_start_df.to_excel(writer, sheet_name=\"Missing_Service_Start\", index=False)\n",
    "\n",
    "    # PA Market Excluded Orders\n",
    "    if len(pa_orders_df) > 0:\n",
    "        pa_output_cols = [c for c in output_cols if c in pa_orders_df.columns]\n",
    "        pa_orders_df[pa_output_cols].to_excel(\n",
    "            writer, sheet_name=\"EXCLUDED_PA_Market\", index=False\n",
    "        )\n",
    "\n",
    "    # All Active Orders (complete list - after PA filter)\n",
    "    orders_df[output_cols].to_excel(writer, sheet_name=\"All_Active_Orders\", index=False)\n",
    "\n",
    "print(f\"\\nâœ… Export complete: {OUTPUT_FILE}\")\n",
    "print(f\"\\n=== Sheets Created ===\")\n",
    "print(f\"   1. Summary - Overview of data quality\")\n",
    "print(f\"   2. Ready_To_Migrate - {len(ready_df):,} orders ready\")\n",
    "print(f\"   3. Missing_BAN_CRITICAL - {len(missing_ban_df):,} orders (MUST FIX)\")\n",
    "print(f\"   4. Missing_A_Location - {len(missing_aloc_df):,} orders\")\n",
    "print(f\"   5. Missing_Node - {len(missing_node_df):,} orders (post-migration)\")\n",
    "print(f\"   6. Missing_Service_Start - {len(missing_start_df):,} orders\")\n",
    "print(f\"   7. EXCLUDED_PA_Market - {len(pa_orders_df):,} orders (not migrating)\")\n",
    "print(f\"   8. All_Active_Orders - {len(orders_df):,} orders (to migrate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "### Priority 1: Fix Missing BAN (3,451 orders)\n",
    "These orders CANNOT be migrated without `Billing_Invoice__c`.\n",
    "\n",
    "**Options:**\n",
    "1. **Find/Create BANs** - Identify correct Billing_Invoice__c for each order\n",
    "2. **Exclude from migration** - If these are internal/test records\n",
    "3. **Create default BAN** - If business approves a catch-all BAN\n",
    "\n",
    "### Priority 2: Fix Missing A Location (201 orders)\n",
    "These need `Address_A__c` populated for `A_Location__c` mapping.\n",
    "\n",
    "### Priority 3: Review Missing Node (15,811 orders)\n",
    "Can be fixed post-migration since `A_Node__c` is not critical for initial load.\n",
    "\n",
    "### Priority 4: Review Missing Service Start (8,875 orders)\n",
    "May need for `Active_Date__c` - review if these are truly activated services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PLACEHOLDER FOR ADDITIONAL ANALYSIS ===\n",
    "\n",
    "# Add custom queries here as needed\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
