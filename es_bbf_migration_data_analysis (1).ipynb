{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES â†’ BBF Migration Data Analysis\n",
    "\n",
    "This notebook analyzes all data required for the ES to BBF Salesforce migration.\n",
    "\n",
    "## Driving Principle\n",
    "**Everything is driven from Active ES Orders** - we migrate only the data needed to support these active services.\n",
    "\n",
    "## Active Order Criteria\n",
    "- **Status** IN ('Activated', 'Suspended (Late Payment)', 'Disconnect in Progress')\n",
    "- **Project_Group__c** NOT LIKE '%PA MARKET DECOM%'\n",
    "\n",
    "## Data Flow\n",
    "```\n",
    "Active Orders (current legacy BAN)\n",
    "    â”‚\n",
    "    â”œâ”€â”€ Legacy Billing_Invoice__c.Id\n",
    "    â”‚       â”‚\n",
    "    â”‚       â””â”€â”€ New BBF BAN (Billing_Invoice__c where Legacy_ES_Id__c = legacy BAN Id)\n",
    "    â”‚               â”‚\n",
    "    â”‚               â””â”€â”€ Account__c â†’ Accounts to migrate\n",
    "    â”‚                       â”‚\n",
    "    â”‚                       â””â”€â”€ Contacts to migrate\n",
    "    â”‚\n",
    "    â”œâ”€â”€ Address_A__c â†’ Locations to migrate\n",
    "    â”‚       â”‚\n",
    "    â”‚       â””â”€â”€ Off_Net__c (Location_1__c or Location_2__c)\n",
    "    â”‚\n",
    "    â””â”€â”€ Address_Z__c â†’ Locations to migrate\n",
    "            â”‚\n",
    "            â””â”€â”€ Off_Net__c (Location_1__c or Location_2__c)\n",
    "```\n",
    "\n",
    "## Output\n",
    "Excel workbook with sheets:\n",
    "1. **Summary** - Overall migration scope and counts\n",
    "2. **Active_Orders** - All qualifying orders (with BBF BAN mapping)\n",
    "3. **BAN_Mapping** - Legacy BAN â†’ New BBF BAN mapping\n",
    "4. **Accounts** - Unique accounts to migrate\n",
    "5. **Contacts** - Contacts for those accounts\n",
    "6. **Locations** - Address_A and Address_Z locations\n",
    "7. **Off_Net** - Off-Net records for migration locations\n",
    "8. **Data_Quality** - Issues requiring attention (orders with BBF BANs only)\n",
    "9. **Orders_Missing_BBF_BAN** - Orders whose legacy BAN has no new BBF BAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: C:\\Users\\vjero\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe\n",
      "Pandas: 2.2.3\n",
      "âœ… Imports successful\n"
     ]
    }
   ],
   "source": [
    "# === SETUP & IMPORTS ===\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "from simple_salesforce import Salesforce\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "print(f\"Python: {sys.executable}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Configuration loaded\n",
      "   Active Statuses: ['Activated', 'Suspended (Late Payment)', 'Disconnect in Progress']\n",
      "   Excluding: Project_Group__c LIKE '%PA MARKET DECOM%'\n",
      "   Output: es_bbf_migration_analysis_20260107_141523.xlsx\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "\n",
    "# ES (Source) Credentials\n",
    "ES_USERNAME = \"sfdcapi@everstream.net\"\n",
    "ES_PASSWORD = \"pV4CAxns8DQtJsBq!\"\n",
    "ES_TOKEN = \"r1uoYiusK19RbrflARydi86TA\"\n",
    "ES_DOMAIN = \"login\"  # 'login' for production, 'test' for sandbox\n",
    "\n",
    "# Active Order Status Filter\n",
    "ACTIVE_STATUSES = [\"Activated\", \"Suspended (Late Payment)\", \"Disconnect in Progress\"]\n",
    "\n",
    "# PA Market Decom Exclusion (Project_Group__c filter)\n",
    "PA_DECOM_FILTER = \"PA MARKET DECOM\"\n",
    "\n",
    "# Output Configuration\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_FILE = f\"es_bbf_migration_analysis_{TIMESTAMP}.xlsx\"\n",
    "\n",
    "print(\"ðŸ“‹ Configuration loaded\")\n",
    "print(f\"   Active Statuses: {ACTIVE_STATUSES}\")\n",
    "print(f\"   Excluding: Project_Group__c LIKE '%{PA_DECOM_FILTER}%'\")\n",
    "print(f\"   Output: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONNECTING TO ES SALESFORCE\n",
      "================================================================================\n",
      "\n",
      "ðŸ”Œ Connecting to ES...\n",
      "âœ… Connected to ES: everstream.my.salesforce.com\n"
     ]
    }
   ],
   "source": [
    "# === CONNECT TO ES SALESFORCE ===\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CONNECTING TO ES SALESFORCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nðŸ”Œ Connecting to ES...\")\n",
    "es_sf = Salesforce(\n",
    "    username=ES_USERNAME,\n",
    "    password=ES_PASSWORD,\n",
    "    security_token=ES_TOKEN,\n",
    "    domain=ES_DOMAIN,\n",
    ")\n",
    "print(f\"âœ… Connected to ES: {es_sf.sf_instance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 1: QUERYING ACTIVE ORDERS\n",
      "================================================================================\n",
      "Querying all orders with active statuses...\n",
      "\n",
      "âœ… Total orders with active statuses: 17,970\n",
      "\n",
      "=== Status Breakdown ===\n",
      "Status\n",
      "Activated                   17684\n",
      "Disconnect in Progress        285\n",
      "Suspended (Late Payment)        1\n"
     ]
    }
   ],
   "source": [
    "# === STEP 1: QUERY ALL ACTIVE ORDERS ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 1: QUERYING ACTIVE ORDERS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "status_filter = \"','\".join(ACTIVE_STATUSES)\n",
    "\n",
    "orders_query = f\"\"\"\n",
    "SELECT \n",
    "    Id, \n",
    "    Name,\n",
    "    Service_ID__c,\n",
    "    Status,\n",
    "    AccountId,\n",
    "    Account.Name,\n",
    "    Billing_Invoice__c,\n",
    "    Address_A__c,\n",
    "    Address_Z__c,\n",
    "    Node__c,\n",
    "    OpportunityId,\n",
    "    Service_Start_Date__c,\n",
    "    Service_End_Date__c,\n",
    "    Service_Provided__c,\n",
    "    SOF_MRC__c,\n",
    "    OSS_Service_ID__c,\n",
    "    Vendor_Circuit_ID__c,\n",
    "    Primary_Product_Family__c,\n",
    "    Primary_Product_Name__c,\n",
    "    Project_Group__c,\n",
    "    CreatedDate,\n",
    "    LastModifiedDate\n",
    "FROM Order\n",
    "WHERE Status IN ('{status_filter}')\n",
    "ORDER BY Service_ID__c\n",
    "\"\"\"\n",
    "\n",
    "print(\"Querying all orders with active statuses...\")\n",
    "result = es_sf.query_all(orders_query)\n",
    "all_orders_df = pd.DataFrame(result[\"records\"])\n",
    "\n",
    "# Flatten Account.Name\n",
    "if \"Account\" in all_orders_df.columns:\n",
    "    all_orders_df[\"Account_Name\"] = all_orders_df[\"Account\"].apply(\n",
    "        lambda x: x.get(\"Name\") if isinstance(x, dict) else None\n",
    "    )\n",
    "    all_orders_df = all_orders_df.drop(\n",
    "        columns=[\"Account\", \"attributes\"], errors=\"ignore\"\n",
    "    )\n",
    "else:\n",
    "    all_orders_df = all_orders_df.drop(columns=[\"attributes\"], errors=\"ignore\")\n",
    "\n",
    "print(f\"\\nâœ… Total orders with active statuses: {len(all_orders_df):,}\")\n",
    "print(f\"\\n=== Status Breakdown ===\")\n",
    "print(all_orders_df[\"Status\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: FILTERING OUT PA MARKET DECOM\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Filter Results:\n",
      "   Total active status orders: 17,970\n",
      "   âŒ Excluded (PA MARKET DECOM): 887\n",
      "   âœ… In scope for migration: 17,083\n",
      "\n",
      "=== PA MARKET DECOM Project Groups ===\n",
      "Project_Group__c\n",
      "PA MARKET DECOM                                    196\n",
      "PHL PA MARKET DECOM                                 76\n",
      "Uniti PA - Sprint Disco PA MARKET DECOM             58\n",
      "PA MARKET DECOM - TMO BAN CHANGE - DO NOT TRACK     20\n",
      "TMO RMSO Y3 $1250 RERATE  PA MARKET DECOM           18\n",
      "Plymouth PA MARKET DECOM                            14\n",
      "Pittston PA MARKET DECOM                            11\n",
      "CPA- PIT PC PA MARKET DECOM                         11\n",
      "PIT KEEP PA MARKET DECOM                            11\n",
      "TMO RMSO Y3 $1250 RERATE PA MARKET DECOM             9\n"
     ]
    }
   ],
   "source": [
    "# === STEP 2: APPLY PA MARKET DECOM FILTER ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: FILTERING OUT PA MARKET DECOM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Separate PA MARKET DECOM orders\n",
    "pa_decom_mask = (\n",
    "    all_orders_df[\"Project_Group__c\"]\n",
    "    .fillna(\"\")\n",
    "    .str.contains(PA_DECOM_FILTER, case=False)\n",
    ")\n",
    "pa_decom_orders_df = all_orders_df[pa_decom_mask].copy()\n",
    "active_orders_df = all_orders_df[~pa_decom_mask].copy()\n",
    "\n",
    "print(f\"\\nðŸ“Š Filter Results:\")\n",
    "print(f\"   Total active status orders: {len(all_orders_df):,}\")\n",
    "print(f\"   âŒ Excluded (PA MARKET DECOM): {len(pa_decom_orders_df):,}\")\n",
    "print(f\"   âœ… In scope for migration: {len(active_orders_df):,}\")\n",
    "\n",
    "if len(pa_decom_orders_df) > 0:\n",
    "    print(f\"\\n=== PA MARKET DECOM Project Groups ===\")\n",
    "    print(pa_decom_orders_df[\"Project_Group__c\"].value_counts().head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: QUERYING NEW BBF BANS\n",
      "================================================================================\n",
      "Querying new BBF BANs (BBF_Ban__c = true, Legacy_ES_Id__c populated)...\n",
      "\n",
      "âœ… Found 2,505 new BBF BANs\n",
      "   Created mapping for 2,505 legacy BANs â†’ new BBF BANs\n"
     ]
    }
   ],
   "source": [
    "# === STEP 3: GET NEW BBF BANS (WITH LEGACY_ES_ID__c) ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: QUERYING NEW BBF BANS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "bbf_ban_query = \"\"\"\n",
    "SELECT \n",
    "    Id,\n",
    "    Name,\n",
    "    Account__c,\n",
    "    Account__r.Name,\n",
    "    Legacy_ES_Id__c,\n",
    "    BBF_Ban__c,\n",
    "    Billing_Address_1__c,\n",
    "    Billing_City__c,\n",
    "    Billing_State__c,\n",
    "    Billing_ZIP__c,\n",
    "    Payment_Terms__c,\n",
    "    Active_Billing__c\n",
    "FROM Billing_Invoice__c\n",
    "WHERE BBF_Ban__c = true\n",
    "  AND Legacy_ES_Id__c != null\n",
    "\"\"\"\n",
    "\n",
    "print(\"Querying new BBF BANs (BBF_Ban__c = true, Legacy_ES_Id__c populated)...\")\n",
    "result = es_sf.query_all(bbf_ban_query)\n",
    "bbf_bans_df = pd.DataFrame(result[\"records\"])\n",
    "\n",
    "if len(bbf_bans_df) > 0:\n",
    "    # Flatten Account name\n",
    "    if \"Account__r\" in bbf_bans_df.columns:\n",
    "        bbf_bans_df[\"Account_Name\"] = bbf_bans_df[\"Account__r\"].apply(\n",
    "            lambda x: x.get(\"Name\") if isinstance(x, dict) else None\n",
    "        )\n",
    "        bbf_bans_df = bbf_bans_df.drop(\n",
    "            columns=[\"Account__r\", \"attributes\"], errors=\"ignore\"\n",
    "        )\n",
    "    else:\n",
    "        bbf_bans_df = bbf_bans_df.drop(columns=[\"attributes\"], errors=\"ignore\")\n",
    "\n",
    "print(f\"\\nâœ… Found {len(bbf_bans_df):,} new BBF BANs\")\n",
    "\n",
    "# Create mapping: Legacy BAN Id -> New BBF BAN record\n",
    "legacy_to_bbf_ban = {}\n",
    "for _, row in bbf_bans_df.iterrows():\n",
    "    legacy_id = row[\"Legacy_ES_Id__c\"]\n",
    "    if legacy_id:\n",
    "        legacy_to_bbf_ban[legacy_id] = row.to_dict()\n",
    "\n",
    "print(f\"   Created mapping for {len(legacy_to_bbf_ban):,} legacy BANs â†’ new BBF BANs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: SIMULATING ORDER REASSIGNMENT TO NEW BBF BANS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Order Reassignment Simulation Results:\n",
      "   âœ… Orders with new BBF BAN mapping: 13,519\n",
      "   âš ï¸  Orders missing new BBF BAN: 25\n",
      "   âŒ Orders with no BAN at all: 3,539\n"
     ]
    }
   ],
   "source": [
    "# === STEP 4: SIMULATE ORDER REASSIGNMENT & IDENTIFY GAPS ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: SIMULATING ORDER REASSIGNMENT TO NEW BBF BANS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Track which orders can be mapped and which cannot\n",
    "orders_with_bbf_ban = []\n",
    "orders_missing_bbf_ban = []\n",
    "orders_missing_any_ban = []\n",
    "\n",
    "for _, order in active_orders_df.iterrows():\n",
    "    legacy_ban_id = order.get(\"Billing_Invoice__c\")\n",
    "\n",
    "    if not legacy_ban_id:\n",
    "        # Order has no BAN at all\n",
    "        orders_missing_any_ban.append(order.to_dict())\n",
    "    elif legacy_ban_id in legacy_to_bbf_ban:\n",
    "        # Order can be mapped to new BBF BAN\n",
    "        order_dict = order.to_dict()\n",
    "        bbf_ban = legacy_to_bbf_ban[legacy_ban_id]\n",
    "        order_dict[\"New_BBF_BAN_Id\"] = bbf_ban[\"Id\"]\n",
    "        order_dict[\"New_BBF_BAN_Name\"] = bbf_ban[\"Name\"]\n",
    "        order_dict[\"New_BBF_BAN_Account__c\"] = bbf_ban[\"Account__c\"]\n",
    "        orders_with_bbf_ban.append(order_dict)\n",
    "    else:\n",
    "        # Order has legacy BAN but no corresponding new BBF BAN\n",
    "        orders_missing_bbf_ban.append(order.to_dict())\n",
    "\n",
    "print(f\"\\nðŸ“Š Order Reassignment Simulation Results:\")\n",
    "print(f\"   âœ… Orders with new BBF BAN mapping: {len(orders_with_bbf_ban):,}\")\n",
    "print(f\"   âš ï¸  Orders missing new BBF BAN: {len(orders_missing_bbf_ban):,}\")\n",
    "print(f\"   âŒ Orders with no BAN at all: {len(orders_missing_any_ban):,}\")\n",
    "\n",
    "# Create DataFrames\n",
    "orders_ready_df = (\n",
    "    pd.DataFrame(orders_with_bbf_ban) if orders_with_bbf_ban else pd.DataFrame()\n",
    ")\n",
    "orders_no_bbf_ban_df = (\n",
    "    pd.DataFrame(orders_missing_bbf_ban) if orders_missing_bbf_ban else pd.DataFrame()\n",
    ")\n",
    "orders_no_ban_df = (\n",
    "    pd.DataFrame(orders_missing_any_ban) if orders_missing_any_ban else pd.DataFrame()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5: IDENTIFYING ACCOUNTS TO MIGRATE\n",
      "================================================================================\n",
      "\n",
      "Found 2,257 unique Accounts from new BBF BANs\n",
      "âœ… Retrieved 2,257 Account records\n",
      "   Already migrated (BBF_New_Id__c populated): 0\n",
      "   Need to migrate: 2,257\n"
     ]
    }
   ],
   "source": [
    "# === STEP 5: IDENTIFY UNIQUE ACCOUNTS TO MIGRATE ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5: IDENTIFYING ACCOUNTS TO MIGRATE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(orders_ready_df) > 0:\n",
    "    # Get unique Account IDs from the new BBF BANs (not from Orders directly)\n",
    "    unique_account_ids = (\n",
    "        orders_ready_df[\"New_BBF_BAN_Account__c\"].dropna().unique().tolist()\n",
    "    )\n",
    "    print(f\"\\nFound {len(unique_account_ids):,} unique Accounts from new BBF BANs\")\n",
    "\n",
    "    # Query Account details\n",
    "    if unique_account_ids:\n",
    "        # Chunk the query to avoid SOQL limits\n",
    "        chunk_size = 150\n",
    "        all_accounts = []\n",
    "\n",
    "        for i in range(0, len(unique_account_ids), chunk_size):\n",
    "            chunk = unique_account_ids[i : i + chunk_size]\n",
    "            ids_str = \"','\".join(chunk)\n",
    "\n",
    "            account_query = f\"\"\"\n",
    "            SELECT Id, Name, Type, Industry, BillingStreet, BillingCity, \n",
    "                   BillingState, BillingPostalCode, BillingCountry,\n",
    "                   Phone, Website, BBF_New_Id__c\n",
    "            FROM Account\n",
    "            WHERE Id IN ('{ids_str}')\n",
    "            \"\"\"\n",
    "            result = es_sf.query_all(account_query)\n",
    "            all_accounts.extend(result[\"records\"])\n",
    "\n",
    "        accounts_df = pd.DataFrame(all_accounts)\n",
    "        if \"attributes\" in accounts_df.columns:\n",
    "            accounts_df = accounts_df.drop(columns=[\"attributes\"])\n",
    "\n",
    "        print(f\"âœ… Retrieved {len(accounts_df):,} Account records\")\n",
    "\n",
    "        # Check how many already migrated\n",
    "        already_migrated = accounts_df[\"BBF_New_Id__c\"].notna().sum()\n",
    "        print(f\"   Already migrated (BBF_New_Id__c populated): {already_migrated:,}\")\n",
    "        print(f\"   Need to migrate: {len(accounts_df) - already_migrated:,}\")\n",
    "else:\n",
    "    accounts_df = pd.DataFrame()\n",
    "    print(\"âš ï¸  No orders ready for migration - cannot identify accounts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 6: IDENTIFYING CONTACTS TO MIGRATE\n",
      "================================================================================\n",
      "âœ… Found 15,769 Contacts for migration accounts\n",
      "   Already migrated: 0\n",
      "   Need to migrate: 15,769\n"
     ]
    }
   ],
   "source": [
    "# === STEP 6: IDENTIFY CONTACTS TO MIGRATE ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 6: IDENTIFYING CONTACTS TO MIGRATE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(accounts_df) > 0:\n",
    "    account_ids = accounts_df[\"Id\"].tolist()\n",
    "\n",
    "    # Chunk the query\n",
    "    chunk_size = 150\n",
    "    all_contacts = []\n",
    "\n",
    "    for i in range(0, len(account_ids), chunk_size):\n",
    "        chunk = account_ids[i : i + chunk_size]\n",
    "        ids_str = \"','\".join(chunk)\n",
    "\n",
    "        contact_query = f\"\"\"\n",
    "        SELECT Id, AccountId, FirstName, LastName, Email, Phone, Title,\n",
    "               MailingStreet, MailingCity, MailingState, MailingPostalCode,\n",
    "               BBF_New_Id__c\n",
    "        FROM Contact\n",
    "        WHERE AccountId IN ('{ids_str}')\n",
    "        \"\"\"\n",
    "        result = es_sf.query_all(contact_query)\n",
    "        all_contacts.extend(result[\"records\"])\n",
    "\n",
    "    contacts_df = pd.DataFrame(all_contacts) if all_contacts else pd.DataFrame()\n",
    "    if len(contacts_df) > 0 and \"attributes\" in contacts_df.columns:\n",
    "        contacts_df = contacts_df.drop(columns=[\"attributes\"])\n",
    "\n",
    "    print(f\"âœ… Found {len(contacts_df):,} Contacts for migration accounts\")\n",
    "\n",
    "    if len(contacts_df) > 0:\n",
    "        already_migrated = contacts_df[\"BBF_New_Id__c\"].notna().sum()\n",
    "        print(f\"   Already migrated: {already_migrated:,}\")\n",
    "        print(f\"   Need to migrate: {len(contacts_df) - already_migrated:,}\")\n",
    "else:\n",
    "    contacts_df = pd.DataFrame()\n",
    "    print(\"âš ï¸  No accounts identified - cannot query contacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 7: IDENTIFYING LOCATIONS TO MIGRATE\n",
      "================================================================================\n",
      "\n",
      "Unique locations referenced by orders with BBF BANs:\n",
      "   Address_A (A Location): 909\n",
      "   Address_Z (Z Location): 10,916\n",
      "   Combined unique: 11,329\n",
      "\n",
      "âœ… Retrieved 11,329 Location records\n",
      "   Already migrated: 0\n",
      "   Need to migrate: 11,329\n"
     ]
    }
   ],
   "source": [
    "# === STEP 7: IDENTIFY LOCATIONS TO MIGRATE ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 7: IDENTIFYING LOCATIONS TO MIGRATE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(orders_ready_df) > 0:\n",
    "    # Get unique Address IDs from orders (Address_A__c and Address_Z__c)\n",
    "    address_a_ids = orders_ready_df[\"Address_A__c\"].dropna().unique().tolist()\n",
    "    address_z_ids = orders_ready_df[\"Address_Z__c\"].dropna().unique().tolist()\n",
    "\n",
    "    # Combine and deduplicate\n",
    "    all_address_ids = list(set(address_a_ids + address_z_ids))\n",
    "\n",
    "    print(f\"\\nUnique locations referenced by orders with BBF BANs:\")\n",
    "    print(f\"   Address_A (A Location): {len(address_a_ids):,}\")\n",
    "    print(f\"   Address_Z (Z Location): {len(address_z_ids):,}\")\n",
    "    print(f\"   Combined unique: {len(all_address_ids):,}\")\n",
    "\n",
    "    if all_address_ids:\n",
    "        # Chunk the query\n",
    "        chunk_size = 150\n",
    "        all_addresses = []\n",
    "\n",
    "        for i in range(0, len(all_address_ids), chunk_size):\n",
    "            chunk = all_address_ids[i : i + chunk_size]\n",
    "            ids_str = \"','\".join(chunk)\n",
    "\n",
    "            address_query = f\"\"\"\n",
    "            SELECT Id, Name, Address__c, City__c, State__c, County__c, Zip__c,\n",
    "                   Complete_Address__c, CLLI__c, Building_Status__c,\n",
    "                   On_Net__c, BBF_New_Id__c\n",
    "            FROM Address__c\n",
    "            WHERE Id IN ('{ids_str}')\n",
    "            \"\"\"\n",
    "            result = es_sf.query_all(address_query)\n",
    "            all_addresses.extend(result[\"records\"])\n",
    "\n",
    "        locations_df = pd.DataFrame(all_addresses) if all_addresses else pd.DataFrame()\n",
    "        if len(locations_df) > 0 and \"attributes\" in locations_df.columns:\n",
    "            locations_df = locations_df.drop(columns=[\"attributes\"])\n",
    "\n",
    "        print(f\"\\nâœ… Retrieved {len(locations_df):,} Location records\")\n",
    "\n",
    "        if len(locations_df) > 0:\n",
    "            already_migrated = locations_df[\"BBF_New_Id__c\"].notna().sum()\n",
    "            print(f\"   Already migrated: {already_migrated:,}\")\n",
    "            print(f\"   Need to migrate: {len(locations_df) - already_migrated:,}\")\n",
    "    else:\n",
    "        locations_df = pd.DataFrame()\n",
    "else:\n",
    "    locations_df = pd.DataFrame()\n",
    "    all_address_ids = []\n",
    "    print(\"âš ï¸  No orders ready - cannot identify locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 8: IDENTIFYING OFF_NET RECORDS TO MIGRATE\n",
      "================================================================================\n",
      "\n",
      "âœ… Found 2,303 Off_Net__c records for migration locations\n",
      "\n",
      "=== Off_Net Status Breakdown ===\n",
      "LEC_Order_Status__c\n",
      "Active                1881\n",
      "Disco                  228\n",
      "Pending                 84\n",
      "Invoice Evaluation      50\n",
      "Pending Disco           43\n",
      "Unknown                 13\n",
      "Soft Disco               2\n",
      "NOC Review               2\n"
     ]
    }
   ],
   "source": [
    "# === STEP 8: IDENTIFY OFF_NET RECORDS TO MIGRATE ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 8: IDENTIFYING OFF_NET RECORDS TO MIGRATE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(all_address_ids) > 0:\n",
    "    # Query Off_Net__c where Location_1__c or Location_2__c is in our location list\n",
    "    chunk_size = 100  # Smaller chunks for OR query\n",
    "    all_offnet = []\n",
    "\n",
    "    for i in range(0, len(all_address_ids), chunk_size):\n",
    "        chunk = all_address_ids[i : i + chunk_size]\n",
    "        ids_str = \"','\".join(chunk)\n",
    "\n",
    "        offnet_query = f\"\"\"\n",
    "        SELECT Id, Name, \n",
    "               Location_1__c, Location_1_Address__c,\n",
    "               Location_2__c, Location_2_Address__c,\n",
    "               Off_Net_Vendor__c, Vendor_Name__c,\n",
    "               Vendor_circuit_Id__c, Internal_Circuit_Id__c,\n",
    "               Cost_MRC__c, Cost_NRC__c, Invoice_MRC__c,\n",
    "               LEC_Order_Status__c, Off_Net_Type__c,\n",
    "               Bandwidth__c, Circuit_Type__c,\n",
    "               Term__c, Term_Agreement_Start_Date__c, Term_Agreement_End_Date__c,\n",
    "               Vendor_Bill_Start_Date__c, Vendor_Bill_Stop_Date__c,\n",
    "               SOF1__c\n",
    "        FROM Off_Net__c\n",
    "        WHERE Location_1__c IN ('{ids_str}')\n",
    "           OR Location_2__c IN ('{ids_str}')\n",
    "        \"\"\"\n",
    "        result = es_sf.query_all(offnet_query)\n",
    "        all_offnet.extend(result[\"records\"])\n",
    "\n",
    "    # Deduplicate (same Off_Net could match both Location_1 and Location_2)\n",
    "    offnet_df = pd.DataFrame(all_offnet) if all_offnet else pd.DataFrame()\n",
    "    if len(offnet_df) > 0:\n",
    "        if \"attributes\" in offnet_df.columns:\n",
    "            offnet_df = offnet_df.drop(columns=[\"attributes\"])\n",
    "        offnet_df = offnet_df.drop_duplicates(subset=[\"Id\"])\n",
    "\n",
    "    print(f\"\\nâœ… Found {len(offnet_df):,} Off_Net__c records for migration locations\")\n",
    "\n",
    "    if len(offnet_df) > 0:\n",
    "        print(f\"\\n=== Off_Net Status Breakdown ===\")\n",
    "        if \"LEC_Order_Status__c\" in offnet_df.columns:\n",
    "            print(offnet_df[\"LEC_Order_Status__c\"].value_counts().to_string())\n",
    "else:\n",
    "    offnet_df = pd.DataFrame()\n",
    "    print(\"âš ï¸  No locations identified - cannot query Off_Net records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 9: DATA QUALITY ANALYSIS (Orders with BBF BANs only)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Data Quality Summary (for 13,519 orders with BBF BANs):\n",
      "                               Issue  Count Percentage Severity                                                Impact\n",
      "         Orders missing Address_A__c     13       0.1%     HIGH            Cannot set A_Location__c on BBF Service__c\n",
      "              Orders missing Node__c  11459      84.8%      LOW Can fix post-migration - A_Node__c/Z_Node__c optional\n",
      "Orders missing Service_Start_Date__c   5905      43.7%   MEDIUM                  Review - may need for Active_Date__c\n"
     ]
    }
   ],
   "source": [
    "# === STEP 9: DATA QUALITY ANALYSIS (ORDERS WITH BBF BANS ONLY) ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 9: DATA QUALITY ANALYSIS (Orders with BBF BANs only)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "data_quality_issues = []\n",
    "\n",
    "# Only analyze orders that have BBF BAN mapping (orders_ready_df)\n",
    "if len(orders_ready_df) > 0:\n",
    "    total_ready = len(orders_ready_df)\n",
    "\n",
    "    # Check for missing Address_A__c\n",
    "    missing_addr_a = orders_ready_df[\"Address_A__c\"].isna().sum()\n",
    "    if missing_addr_a > 0:\n",
    "        data_quality_issues.append(\n",
    "            {\n",
    "                \"Issue\": \"Orders missing Address_A__c\",\n",
    "                \"Count\": missing_addr_a,\n",
    "                \"Percentage\": f\"{missing_addr_a/total_ready*100:.1f}%\",\n",
    "                \"Severity\": \"HIGH\",\n",
    "                \"Impact\": \"Cannot set A_Location__c on BBF Service__c\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Check for missing Address_Z__c\n",
    "    missing_addr_z = orders_ready_df[\"Address_Z__c\"].isna().sum()\n",
    "    if missing_addr_z > 0:\n",
    "        data_quality_issues.append(\n",
    "            {\n",
    "                \"Issue\": \"Orders missing Address_Z__c\",\n",
    "                \"Count\": missing_addr_z,\n",
    "                \"Percentage\": f\"{missing_addr_z/total_ready*100:.1f}%\",\n",
    "                \"Severity\": \"MEDIUM\",\n",
    "                \"Impact\": \"Cannot set Z_Location__c on BBF Service__c\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Check for missing Node__c\n",
    "    missing_node = orders_ready_df[\"Node__c\"].isna().sum()\n",
    "    if missing_node > 0:\n",
    "        data_quality_issues.append(\n",
    "            {\n",
    "                \"Issue\": \"Orders missing Node__c\",\n",
    "                \"Count\": missing_node,\n",
    "                \"Percentage\": f\"{missing_node/total_ready*100:.1f}%\",\n",
    "                \"Severity\": \"LOW\",\n",
    "                \"Impact\": \"Can fix post-migration - A_Node__c/Z_Node__c optional\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Check for missing Service_Start_Date__c\n",
    "    missing_start = orders_ready_df[\"Service_Start_Date__c\"].isna().sum()\n",
    "    if missing_start > 0:\n",
    "        data_quality_issues.append(\n",
    "            {\n",
    "                \"Issue\": \"Orders missing Service_Start_Date__c\",\n",
    "                \"Count\": missing_start,\n",
    "                \"Percentage\": f\"{missing_start/total_ready*100:.1f}%\",\n",
    "                \"Severity\": \"MEDIUM\",\n",
    "                \"Impact\": \"Review - may need for Active_Date__c\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Check for missing SOF_MRC__c\n",
    "    missing_mrc = orders_ready_df[\"SOF_MRC__c\"].isna().sum()\n",
    "    if missing_mrc > 0:\n",
    "        data_quality_issues.append(\n",
    "            {\n",
    "                \"Issue\": \"Orders missing SOF_MRC__c\",\n",
    "                \"Count\": missing_mrc,\n",
    "                \"Percentage\": f\"{missing_mrc/total_ready*100:.1f}%\",\n",
    "                \"Severity\": \"MEDIUM\",\n",
    "                \"Impact\": \"MRC value not available for Service__c\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "data_quality_df = pd.DataFrame(data_quality_issues)\n",
    "\n",
    "print(f\"\\nðŸ“Š Data Quality Summary (for {len(orders_ready_df):,} orders with BBF BANs):\")\n",
    "if len(data_quality_df) > 0:\n",
    "    print(data_quality_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"   âœ… No data quality issues found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 10: CREATING BAN MAPPING TABLE\n",
      "================================================================================\n",
      "\n",
      "âœ… Created mapping for 2,504 BANs\n",
      "   Total orders covered: 13,519\n"
     ]
    }
   ],
   "source": [
    "# === STEP 10: CREATE BAN MAPPING TABLE ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 10: CREATING BAN MAPPING TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get unique legacy BANs from orders ready to migrate\n",
    "if len(orders_ready_df) > 0:\n",
    "    ban_mapping_data = []\n",
    "\n",
    "    # Group orders by legacy BAN to get counts\n",
    "    legacy_ban_counts = orders_ready_df.groupby(\"Billing_Invoice__c\").size().to_dict()\n",
    "\n",
    "    for legacy_id, bbf_ban in legacy_to_bbf_ban.items():\n",
    "        order_count = legacy_ban_counts.get(legacy_id, 0)\n",
    "        if order_count > 0:  # Only include BANs that have orders\n",
    "            ban_mapping_data.append(\n",
    "                {\n",
    "                    \"Legacy_BAN_Id\": legacy_id,\n",
    "                    \"New_BBF_BAN_Id\": bbf_ban[\"Id\"],\n",
    "                    \"New_BBF_BAN_Name\": bbf_ban[\"Name\"],\n",
    "                    \"Account__c\": bbf_ban[\"Account__c\"],\n",
    "                    \"Account_Name\": bbf_ban.get(\"Account_Name\"),\n",
    "                    \"Order_Count\": order_count,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    ban_mapping_df = pd.DataFrame(ban_mapping_data)\n",
    "    print(f\"\\nâœ… Created mapping for {len(ban_mapping_df):,} BANs\")\n",
    "    print(f\"   Total orders covered: {ban_mapping_df['Order_Count'].sum():,}\")\n",
    "else:\n",
    "    ban_mapping_df = pd.DataFrame()\n",
    "    print(\"âš ï¸  No BAN mapping created - no orders ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 11: MIGRATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      " Category                       Metric Count                                           Notes\n",
      "   ORDERS                                                                                   \n",
      "            Total Active Status Orders 17970               All orders with qualifying status\n",
      "            Excluded (PA MARKET DECOM)   887     Project_Group__c contains 'PA MARKET DECOM'\n",
      "                In Scope for Migration 17083            Active orders not in PA MARKET DECOM\n",
      "          Ready (have BBF BAN mapping) 13519                             Can be migrated now\n",
      "                       Missing BBF BAN    25                        Need new BBF BAN created\n",
      "                       Missing ANY BAN  3539                       CRITICAL - cannot migrate\n",
      "                                                                                            \n",
      "     BANS                                                                                   \n",
      "                New BBF BANs Available  2505         Billing_Invoice__c with BBF_Ban__c=true\n",
      "           BANs with Orders to Migrate  2504                    BANs that have active orders\n",
      "                                                                                            \n",
      " ACCOUNTS                                                                                   \n",
      "                   Accounts to Migrate  2257                   Unique accounts from BBF BANs\n",
      "                                                                                            \n",
      " CONTACTS                                                                                   \n",
      "                   Contacts to Migrate 15769                 Contacts for migration accounts\n",
      "                                                                                            \n",
      "LOCATIONS                                                                                   \n",
      "                  Locations to Migrate 11329 Address_A + Address_Z from orders with BBF BANs\n",
      "                                                                                            \n",
      "  OFF_NET                                                                                   \n",
      "            Off_Net Records to Migrate  2303                 Off_Net for migration locations\n"
     ]
    }
   ],
   "source": [
    "# === STEP 11: GENERATE SUMMARY ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 11: MIGRATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_data = [\n",
    "    {\"Category\": \"ORDERS\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"Total Active Status Orders\",\n",
    "        \"Count\": len(all_orders_df),\n",
    "        \"Notes\": \"All orders with qualifying status\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"Excluded (PA MARKET DECOM)\",\n",
    "        \"Count\": len(pa_decom_orders_df),\n",
    "        \"Notes\": \"Project_Group__c contains 'PA MARKET DECOM'\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"In Scope for Migration\",\n",
    "        \"Count\": len(active_orders_df),\n",
    "        \"Notes\": \"Active orders not in PA MARKET DECOM\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"Ready (have BBF BAN mapping)\",\n",
    "        \"Count\": len(orders_ready_df),\n",
    "        \"Notes\": \"Can be migrated now\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"Missing BBF BAN\",\n",
    "        \"Count\": len(orders_no_bbf_ban_df),\n",
    "        \"Notes\": \"Need new BBF BAN created\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"Missing ANY BAN\",\n",
    "        \"Count\": len(orders_no_ban_df),\n",
    "        \"Notes\": \"CRITICAL - cannot migrate\",\n",
    "    },\n",
    "    {\"Category\": \"\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\"Category\": \"BANS\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"New BBF BANs Available\",\n",
    "        \"Count\": len(bbf_bans_df),\n",
    "        \"Notes\": \"Billing_Invoice__c with BBF_Ban__c=true\",\n",
    "    },\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"BANs with Orders to Migrate\",\n",
    "        \"Count\": len(ban_mapping_df) if len(ban_mapping_df) > 0 else 0,\n",
    "        \"Notes\": \"BANs that have active orders\",\n",
    "    },\n",
    "    {\"Category\": \"\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\"Category\": \"ACCOUNTS\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"Accounts to Migrate\",\n",
    "        \"Count\": len(accounts_df),\n",
    "        \"Notes\": \"Unique accounts from BBF BANs\",\n",
    "    },\n",
    "    {\"Category\": \"\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\"Category\": \"CONTACTS\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"Contacts to Migrate\",\n",
    "        \"Count\": len(contacts_df),\n",
    "        \"Notes\": \"Contacts for migration accounts\",\n",
    "    },\n",
    "    {\"Category\": \"\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\"Category\": \"LOCATIONS\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"Locations to Migrate\",\n",
    "        \"Count\": len(locations_df),\n",
    "        \"Notes\": \"Address_A + Address_Z from orders with BBF BANs\",\n",
    "    },\n",
    "    {\"Category\": \"\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\"Category\": \"OFF_NET\", \"Metric\": \"\", \"Count\": \"\", \"Notes\": \"\"},\n",
    "    {\n",
    "        \"Category\": \"\",\n",
    "        \"Metric\": \"Off_Net Records to Migrate\",\n",
    "        \"Count\": len(offnet_df),\n",
    "        \"Notes\": \"Off_Net for migration locations\",\n",
    "    },\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 12: EXPORTING TO EXCEL\n",
      "================================================================================\n",
      "   âœ… Summary sheet created\n",
      "   âœ… Active_Orders sheet created (13,519 rows)\n",
      "   âœ… BAN_Mapping sheet created (2,504 rows)\n",
      "   âœ… Accounts sheet created (2,257 rows)\n",
      "   âœ… Contacts sheet created (15,769 rows)\n",
      "   âœ… Locations sheet created (11,329 rows)\n",
      "   âœ… Off_Net sheet created (2,303 rows)\n",
      "   âœ… Data_Quality sheet created (3 issues)\n",
      "   âœ… Orders_Missing_BBF_BAN sheet created (25 rows)\n",
      "   âœ… Excluded_PA_DECOM sheet created (887 rows)\n",
      "\n",
      "âœ… Excel file saved: es_bbf_migration_analysis_20260107_141523.xlsx\n"
     ]
    }
   ],
   "source": [
    "# === STEP 12: EXPORT TO EXCEL ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 12: EXPORTING TO EXCEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "wb = Workbook()\n",
    "ws_summary = wb.active\n",
    "ws_summary.title = \"Summary\"\n",
    "\n",
    "# Styles\n",
    "header_font = Font(bold=True, size=12, color=\"FFFFFF\")\n",
    "header_fill = PatternFill(start_color=\"4472C4\", end_color=\"4472C4\", fill_type=\"solid\")\n",
    "thin_border = Border(\n",
    "    left=Side(style=\"thin\"),\n",
    "    right=Side(style=\"thin\"),\n",
    "    top=Side(style=\"thin\"),\n",
    "    bottom=Side(style=\"thin\"),\n",
    ")\n",
    "\n",
    "# --- SHEET 1: Summary ---\n",
    "ws_summary.append([\"ES â†’ BBF Migration Analysis\"])\n",
    "ws_summary[\"A1\"].font = Font(bold=True, size=16)\n",
    "ws_summary.append([f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"])\n",
    "ws_summary.append([])\n",
    "\n",
    "headers = [\"Category\", \"Metric\", \"Count\", \"Notes\"]\n",
    "ws_summary.append(headers)\n",
    "for col, header in enumerate(headers, 1):\n",
    "    cell = ws_summary.cell(row=4, column=col)\n",
    "    cell.font = header_font\n",
    "    cell.fill = header_fill\n",
    "\n",
    "for _, row in summary_df.iterrows():\n",
    "    ws_summary.append([row[\"Category\"], row[\"Metric\"], row[\"Count\"], row[\"Notes\"]])\n",
    "\n",
    "ws_summary.column_dimensions[\"A\"].width = 15\n",
    "ws_summary.column_dimensions[\"B\"].width = 35\n",
    "ws_summary.column_dimensions[\"C\"].width = 12\n",
    "ws_summary.column_dimensions[\"D\"].width = 50\n",
    "\n",
    "print(\"   âœ… Summary sheet created\")\n",
    "\n",
    "# --- SHEET 2: Active Orders ---\n",
    "if len(orders_ready_df) > 0:\n",
    "    ws_orders = wb.create_sheet(\"Active_Orders\")\n",
    "    order_cols = [\n",
    "        \"Id\",\n",
    "        \"Name\",\n",
    "        \"Service_ID__c\",\n",
    "        \"Status\",\n",
    "        \"Account_Name\",\n",
    "        \"Billing_Invoice__c\",\n",
    "        \"New_BBF_BAN_Id\",\n",
    "        \"New_BBF_BAN_Name\",\n",
    "        \"Address_A__c\",\n",
    "        \"Address_Z__c\",\n",
    "        \"SOF_MRC__c\",\n",
    "        \"Service_Start_Date__c\",\n",
    "    ]\n",
    "    order_cols = [c for c in order_cols if c in orders_ready_df.columns]\n",
    "\n",
    "    ws_orders.append(order_cols)\n",
    "    for col, header in enumerate(order_cols, 1):\n",
    "        cell = ws_orders.cell(row=1, column=col)\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "\n",
    "    for _, row in orders_ready_df[order_cols].iterrows():\n",
    "        ws_orders.append(list(row))\n",
    "\n",
    "    ws_orders.freeze_panes = \"A2\"\n",
    "    print(f\"   âœ… Active_Orders sheet created ({len(orders_ready_df):,} rows)\")\n",
    "\n",
    "# --- SHEET 3: BAN Mapping ---\n",
    "if len(ban_mapping_df) > 0:\n",
    "    ws_ban = wb.create_sheet(\"BAN_Mapping\")\n",
    "    headers = list(ban_mapping_df.columns)\n",
    "    ws_ban.append(headers)\n",
    "    for col, header in enumerate(headers, 1):\n",
    "        cell = ws_ban.cell(row=1, column=col)\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "\n",
    "    for _, row in ban_mapping_df.iterrows():\n",
    "        ws_ban.append(list(row))\n",
    "\n",
    "    ws_ban.freeze_panes = \"A2\"\n",
    "    print(f\"   âœ… BAN_Mapping sheet created ({len(ban_mapping_df):,} rows)\")\n",
    "\n",
    "# --- SHEET 4: Accounts ---\n",
    "if len(accounts_df) > 0:\n",
    "    ws_acct = wb.create_sheet(\"Accounts\")\n",
    "    headers = list(accounts_df.columns)\n",
    "    ws_acct.append(headers)\n",
    "    for col, header in enumerate(headers, 1):\n",
    "        cell = ws_acct.cell(row=1, column=col)\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "\n",
    "    for _, row in accounts_df.iterrows():\n",
    "        ws_acct.append(list(row))\n",
    "\n",
    "    ws_acct.freeze_panes = \"A2\"\n",
    "    print(f\"   âœ… Accounts sheet created ({len(accounts_df):,} rows)\")\n",
    "\n",
    "# --- SHEET 5: Contacts ---\n",
    "if len(contacts_df) > 0:\n",
    "    ws_contact = wb.create_sheet(\"Contacts\")\n",
    "    headers = list(contacts_df.columns)\n",
    "    ws_contact.append(headers)\n",
    "    for col, header in enumerate(headers, 1):\n",
    "        cell = ws_contact.cell(row=1, column=col)\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "\n",
    "    for _, row in contacts_df.iterrows():\n",
    "        ws_contact.append(list(row))\n",
    "\n",
    "    ws_contact.freeze_panes = \"A2\"\n",
    "    print(f\"   âœ… Contacts sheet created ({len(contacts_df):,} rows)\")\n",
    "\n",
    "# --- SHEET 6: Locations ---\n",
    "if len(locations_df) > 0:\n",
    "    ws_loc = wb.create_sheet(\"Locations\")\n",
    "    headers = list(locations_df.columns)\n",
    "    ws_loc.append(headers)\n",
    "    for col, header in enumerate(headers, 1):\n",
    "        cell = ws_loc.cell(row=1, column=col)\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "\n",
    "    for _, row in locations_df.iterrows():\n",
    "        ws_loc.append(list(row))\n",
    "\n",
    "    ws_loc.freeze_panes = \"A2\"\n",
    "    print(f\"   âœ… Locations sheet created ({len(locations_df):,} rows)\")\n",
    "\n",
    "# --- SHEET 7: Off_Net ---\n",
    "if len(offnet_df) > 0:\n",
    "    ws_offnet = wb.create_sheet(\"Off_Net\")\n",
    "    headers = list(offnet_df.columns)\n",
    "    ws_offnet.append(headers)\n",
    "    for col, header in enumerate(headers, 1):\n",
    "        cell = ws_offnet.cell(row=1, column=col)\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "\n",
    "    for _, row in offnet_df.iterrows():\n",
    "        ws_offnet.append(list(row))\n",
    "\n",
    "    ws_offnet.freeze_panes = \"A2\"\n",
    "    print(f\"   âœ… Off_Net sheet created ({len(offnet_df):,} rows)\")\n",
    "\n",
    "# --- SHEET 8: Data Quality ---\n",
    "if len(data_quality_df) > 0:\n",
    "    ws_dq = wb.create_sheet(\"Data_Quality\")\n",
    "    headers = list(data_quality_df.columns)\n",
    "    ws_dq.append(headers)\n",
    "    for col, header in enumerate(headers, 1):\n",
    "        cell = ws_dq.cell(row=1, column=col)\n",
    "        cell.font = header_font\n",
    "        cell.fill = PatternFill(\n",
    "            start_color=\"FF4444\", end_color=\"FF4444\", fill_type=\"solid\"\n",
    "        )\n",
    "\n",
    "    for _, row in data_quality_df.iterrows():\n",
    "        ws_dq.append(list(row))\n",
    "\n",
    "    severity_colors = {\n",
    "        \"CRITICAL\": \"FF6666\",\n",
    "        \"HIGH\": \"FFAA66\",\n",
    "        \"MEDIUM\": \"FFFF66\",\n",
    "        \"LOW\": \"66FF66\",\n",
    "    }\n",
    "    for row_idx in range(2, len(data_quality_df) + 2):\n",
    "        severity = ws_dq.cell(row=row_idx, column=4).value\n",
    "        if severity in severity_colors:\n",
    "            for col in range(1, len(headers) + 1):\n",
    "                ws_dq.cell(row=row_idx, column=col).fill = PatternFill(\n",
    "                    start_color=severity_colors[severity],\n",
    "                    end_color=severity_colors[severity],\n",
    "                    fill_type=\"solid\",\n",
    "                )\n",
    "\n",
    "    ws_dq.freeze_panes = \"A2\"\n",
    "    print(f\"   âœ… Data_Quality sheet created ({len(data_quality_df):,} issues)\")\n",
    "\n",
    "# --- SHEET 9: Orders Missing BBF BAN ---\n",
    "if len(orders_no_bbf_ban_df) > 0:\n",
    "    ws_missing = wb.create_sheet(\"Orders_Missing_BBF_BAN\")\n",
    "    cols = [\n",
    "        \"Id\",\n",
    "        \"Name\",\n",
    "        \"Service_ID__c\",\n",
    "        \"Status\",\n",
    "        \"Account_Name\",\n",
    "        \"Billing_Invoice__c\",\n",
    "        \"SOF_MRC__c\",\n",
    "    ]\n",
    "    cols = [c for c in cols if c in orders_no_bbf_ban_df.columns]\n",
    "\n",
    "    ws_missing.append(cols)\n",
    "    for col, header in enumerate(cols, 1):\n",
    "        cell = ws_missing.cell(row=1, column=col)\n",
    "        cell.font = header_font\n",
    "        cell.fill = PatternFill(\n",
    "            start_color=\"FF4444\", end_color=\"FF4444\", fill_type=\"solid\"\n",
    "        )\n",
    "\n",
    "    for _, row in orders_no_bbf_ban_df[cols].iterrows():\n",
    "        ws_missing.append(list(row))\n",
    "\n",
    "    ws_missing.freeze_panes = \"A2\"\n",
    "    print(\n",
    "        f\"   âœ… Orders_Missing_BBF_BAN sheet created ({len(orders_no_bbf_ban_df):,} rows)\"\n",
    "    )\n",
    "\n",
    "# --- SHEET 10: PA MARKET DECOM (Excluded) ---\n",
    "if len(pa_decom_orders_df) > 0:\n",
    "    ws_excluded = wb.create_sheet(\"Excluded_PA_DECOM\")\n",
    "    cols = [\"Id\", \"Name\", \"Service_ID__c\", \"Status\", \"Project_Group__c\", \"Account_Name\"]\n",
    "    cols = [c for c in cols if c in pa_decom_orders_df.columns]\n",
    "\n",
    "    ws_excluded.append(cols)\n",
    "    for col, header in enumerate(cols, 1):\n",
    "        cell = ws_excluded.cell(row=1, column=col)\n",
    "        cell.font = header_font\n",
    "        cell.fill = PatternFill(\n",
    "            start_color=\"808080\", end_color=\"808080\", fill_type=\"solid\"\n",
    "        )\n",
    "\n",
    "    for _, row in pa_decom_orders_df[cols].iterrows():\n",
    "        ws_excluded.append(list(row))\n",
    "\n",
    "    ws_excluded.freeze_panes = \"A2\"\n",
    "    print(f\"   âœ… Excluded_PA_DECOM sheet created ({len(pa_decom_orders_df):,} rows)\")\n",
    "\n",
    "wb.save(OUTPUT_FILE)\n",
    "print(f\"\\nâœ… Excel file saved: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MIGRATION DATA ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š SUMMARY\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Active Orders (in scope):     17,083\n",
      "  â”œâ”€ Ready to migrate:        13,519\n",
      "  â”œâ”€ Missing BBF BAN:         25\n",
      "  â””â”€ Missing ANY BAN:         3,539\n",
      "\n",
      "Records to Migrate:\n",
      "  â”œâ”€ Accounts:                2,257\n",
      "  â”œâ”€ Contacts:                15,769\n",
      "  â”œâ”€ Locations:               11,329\n",
      "  â”œâ”€ Off_Net:                 2,303\n",
      "  â””â”€ BANs (with orders):      2,504\n",
      "\n",
      "Excluded:\n",
      "  â””â”€ PA MARKET DECOM:         887\n",
      "\n",
      "Output: es_bbf_migration_analysis_20260107_141523.xlsx\n",
      "\n",
      "âš ï¸  ACTION REQUIRED:\n",
      "   â€¢ 25 orders need new BBF BANs created\n",
      "   â€¢ 3,539 orders have no BAN - CANNOT migrate\n",
      "\n",
      "   Review the Excel output for details.\n"
     ]
    }
   ],
   "source": [
    "# === FINAL SUMMARY ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MIGRATION DATA ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "ðŸ“Š SUMMARY\n",
    "{'â”€'*40}\n",
    "Active Orders (in scope):     {len(active_orders_df):,}\n",
    "  â”œâ”€ Ready to migrate:        {len(orders_ready_df):,}\n",
    "  â”œâ”€ Missing BBF BAN:         {len(orders_no_bbf_ban_df):,}\n",
    "  â””â”€ Missing ANY BAN:         {len(orders_no_ban_df):,}\n",
    "\n",
    "Records to Migrate:\n",
    "  â”œâ”€ Accounts:                {len(accounts_df):,}\n",
    "  â”œâ”€ Contacts:                {len(contacts_df):,}\n",
    "  â”œâ”€ Locations:               {len(locations_df):,}\n",
    "  â”œâ”€ Off_Net:                 {len(offnet_df):,}\n",
    "  â””â”€ BANs (with orders):      {len(ban_mapping_df):,}\n",
    "\n",
    "Excluded:\n",
    "  â””â”€ PA MARKET DECOM:         {len(pa_decom_orders_df):,}\n",
    "\n",
    "Output: {OUTPUT_FILE}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "if len(orders_no_bbf_ban_df) > 0 or len(orders_no_ban_df) > 0:\n",
    "    print(\"âš ï¸  ACTION REQUIRED:\")\n",
    "    if len(orders_no_bbf_ban_df) > 0:\n",
    "        print(f\"   â€¢ {len(orders_no_bbf_ban_df):,} orders need new BBF BANs created\")\n",
    "    if len(orders_no_ban_df) > 0:\n",
    "        print(f\"   â€¢ {len(orders_no_ban_df):,} orders have no BAN - CANNOT migrate\")\n",
    "    print(\"\\n   Review the Excel output for details.\")\n",
    "else:\n",
    "    print(\"âœ… All orders ready for migration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "### If Orders Missing BBF BAN > 0:\n",
    "1. Review the `Orders_Missing_BBF_BAN` sheet\n",
    "2. Identify the legacy BANs that need new BBF BANs created\n",
    "3. Create the new BBF BANs in ES with `BBF_Ban__c = true` and `Legacy_ES_Id__c` = legacy BAN Id\n",
    "4. Re-run this analysis\n",
    "\n",
    "### Migration Execution Order:\n",
    "1. **Account** - `es_bbf_account_migration.ipynb`\n",
    "2. **Contact** - `es_bbf_contact_migration.ipynb`\n",
    "3. **Location** - `es_bbf_location_migration.ipynb`\n",
    "4. **BAN** - `es_bbf_ban_migration.ipynb`\n",
    "5. **Service** - `es_bbf_service_migration.ipynb` (Order â†’ Service__c)\n",
    "6. **Service_Charge** - `es_bbf_service_charge_migration.ipynb` (OrderItem â†’ Service_Charge__c)\n",
    "7. **Off_Net** - `es_bbf_offnet_migration.ipynb`\n",
    "8. **BAN_Contact** - (auto-created or derived)\n",
    "\n",
    "### Manual Setup (outside notebooks):\n",
    "- Product2\n",
    "- Pricebook2  \n",
    "- PricebookEntry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
